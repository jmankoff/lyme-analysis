{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from IPython.core.display import HTML\n",
    "from scipy.stats import ttest_rel\n",
    "import matplotlib.pyplot as plt\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Helpers.ipynb\n",
    "DEBUG=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions for Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     50,
     61,
     86
    ]
   },
   "outputs": [],
   "source": [
    "# To load a survey, we first read the csv file, \n",
    "# then use the transdict to convert the headers to standard names, \n",
    "# and drop the columns we are not interested in. \n",
    "# Finally, we drop any entries that do not have an appropriate participant ID (>max_PID)\n",
    "# Finally performs data cleaning. \n",
    "# @filedir the location of the data files\n",
    "# @dataconfig the config file\n",
    "def load_surveys(config, dataconfig):\n",
    "    \"\"\"Loads a survey. Drops columns not of interest and any entry \n",
    "    without a valid participant ID (>max_PID) \n",
    "    Also transforms column names to a standard set.\"\"\"\n",
    "    \n",
    "    surveydir = config[\"surveydir\"]\n",
    "    configdir = config[\"configdir\"]\n",
    "    surveys = dataconfig[\"surveys\"]\n",
    "    results = {}\n",
    "    \n",
    "    for survey in surveys:\n",
    "        print(\"--------------------------------------------------\")\n",
    "        print(\"loading survey: \", survey)\n",
    "        print(\"--------------------------------------------------\")\n",
    "\n",
    "        survey_config = dataconfig[survey]\n",
    "        file = surveydir + survey_config[\"file\"]\n",
    "\n",
    "        # Load the json file that has the transdict in it\n",
    "        with open(configdir + survey_config[\"transdict\"], 'r') as file_obj:\n",
    "            transdict = json.load(file_obj)\n",
    "            file_obj.close()\n",
    "            \n",
    "        # the unique tag for this survey\n",
    "        name = survey_config[\"name\"]\n",
    "        # index variables that should have the same name in all surveys\n",
    "        index = survey_config[\"index\"]\n",
    "        # max_PID the maximum PID number for a participant\n",
    "        max_PID = survey_config[\"max_pid\"]\n",
    "        # the maximum number of survey questions that can have no answer. If -1, don't drop\n",
    "        max_skip = survey_config[\"max_skip\"]\n",
    "        # specialty cleaning code for this survey (by default does nothing)\n",
    "        custom_cleaning = eval(survey_config[\"cleaning\"])\n",
    "        # index variable for merging\n",
    "        mergeindex = dataconfig[\"mergeindex\"]\n",
    "\n",
    "        print(survey_config[\"notes\"])\n",
    "        \n",
    "        #################################### read the survey in ##########################################\n",
    "        df = pd.read_csv(file, header=[0,1]) \n",
    "        printD(df.shape)\n",
    "        \n",
    "        #################################### set up column names for transdict ###########################\n",
    "        # participant ID (PID) should not have a survey-specific name; same with recordId (ID)\n",
    "        # Everything else *SHOULD* have name after it.\n",
    "#         for key in transdict:\n",
    "#             val = transdict[key]\n",
    "#             if (not (val in index)):\n",
    "#                 transdict[key] = val+\"_\"+name# set up column names for dropping from survey\n",
    "\n",
    "        printD(\"rename columns\")\n",
    "        columns = df.columns.values\n",
    "        columns = np.array([transdict[x[0]] for x in columns])\n",
    "        df.columns = columns\n",
    "        #display(HTML(df.head(20).to_html()))\n",
    "        printD(df.shape)\n",
    "\n",
    "        #################################### set up column names for dropping from transdict #############\n",
    "        printD(\"drop columns\")\n",
    "        # the columns to drop (that we don't need) (by default drop_cols)\n",
    "        drop = dataconfig[\"drop\"]\n",
    "#         drop = [item if item in index else item + \"_\" + name for item in drop]\n",
    "        drop = np.intersect1d(columns,drop)\n",
    "        printD(drop)\n",
    "        df = df.drop(columns=drop)\n",
    "        printD(df.shape)\n",
    "\n",
    "        #################################### check for correct PID size ###################################\n",
    "        print(\"todo: have a list of correct PIDs rather than a max pid\")\n",
    "        query = 'PID <= ' + str(max_PID)\n",
    "        printD(\"dropping people who did not have a correct PID, #=\", df.query(query).shape[0])\n",
    "        df = df.query(query)\n",
    "        printD(df.shape)\n",
    "\n",
    "        #################################### check for completion (qualtrics variable) ####################\n",
    "        printD(\"dropping surveys with incomplete status\")\n",
    "        try:\n",
    "            valid = df['status'] == 0\n",
    "            printD(\"dropping surveys with a response value of 0 (not complete)\")\n",
    "            df = df[valid]\n",
    "        except:\n",
    "            print(\"survey has not status\")\n",
    "        printD(df.shape)\n",
    "    \n",
    "         #################################### drop any row with at least max_skip entries missing #########\n",
    "        if (max_skip > 0):\n",
    "            printD(\"dropping people who didn't answer lots of questions\")\n",
    "            na_list = df.isnull().sum(axis=1)\n",
    "            printD(\"dropping people who skipped at least\", max_skip, \"questions. numskipped for each participant: \", \n",
    "                   df.isnull().sum(axis=1).tolist())\n",
    "            print(\"Dropping people who didn't answer lots of questions\", df[\"PID\"][na_list > max_skip].tolist())\n",
    "#             print(na_th_id)\n",
    "            df = df[na_list <= max_skip]\n",
    "            printD(df.shape)\n",
    "        \n",
    "        #################################### fill NAs with appropriate choices #############################\n",
    "        # By default:\n",
    "        # Dates should be ignored. text should be changed to blanks (these are text columns).\n",
    "        # And numeric columns should be converted to -99\n",
    "        # And everything else should be converted to ''\n",
    "        for column in df.columns.values:\n",
    "            printD(column)\n",
    "            try: \n",
    "                df[column] = pd.to_numeric(df[column], downcast = \"integer\")\n",
    "#                 df[column] = df[column].fillna(-1)\n",
    "#                 df[column] = df[column].apply(np.int64)\n",
    "                printD(\"number\")\n",
    "            except: \n",
    "                try: \n",
    "                    df[column] = pd.to_datetime(df[column])\n",
    "                    printD(\"date\")\n",
    "                except:\n",
    "                    df[column] = df[column].fillna('')\n",
    "                    printD(\"text\")\n",
    "        \n",
    "         #################################### check for duplicates #############################\n",
    "\n",
    "        print(\"finding duplicates\")\n",
    "        dups = find_duplicate_pids(max_PID, df)\n",
    "        print(\"duplicates\", dups)\n",
    "    \n",
    "        #################################### run custom cleaning function #############################\n",
    "\n",
    "        printD(\"custom cleaning\")\n",
    "        df = custom_cleaning(df)\n",
    "        printD(df.shape)\n",
    "\n",
    "        #################################### check that diffs are resolved #############################\n",
    "        dups = find_duplicate_pids(max_PID, df)\n",
    "        print(\"duplicates\", dups)\n",
    "        print_diffs(max_PID, df)\n",
    "\n",
    "        #################################### set the index up #############################\n",
    "        # Defaults into the first value in the index array\n",
    "        print(\"setting index\")\n",
    "        df[mergeindex] = df[index[0]]\n",
    "        df = df.set_index(mergeindex)\n",
    "        df[mergeindex] = df.index\n",
    "\n",
    "        \n",
    "        print(df.shape)\n",
    "#         display(HTML(df.head(n=2).to_html()))\n",
    "        results[survey] = df\n",
    "    return results\n",
    "\n",
    "                \n",
    "def find_duplicate_pids(max_PID, survey):\n",
    "    \"\"\"Counts the numbert of times each PID from 0 to max_PID occurs in survey.\n",
    "        Then returns a list of those that occur more than once\"\"\"\n",
    "    pids = np.zeros(max_PID)\n",
    "    printD(max_PID)\n",
    "    printD(pids)\n",
    "    for item in survey['PID']:\n",
    "        printD(item)\n",
    "        pids[item] += 1 \n",
    "    printD(pids)\n",
    "    pids = np.where(pids>1.0)[0]\n",
    "    return pids\n",
    "\n",
    "#PrintDs the contents of the columns that differ, for each column that has a difference\n",
    "# This is done for each PID for which there are duplicates.\n",
    "def print_diffs(max_PID, survey):\n",
    "    \"\"\"PrintDs the contents of the columns that differ, for each column that has a difference\n",
    "    This is done for each PID for which there are duplicates.\"\"\"\n",
    "    print(\"printing diffs\")\n",
    "    pids = find_duplicate_pids(max_PID, survey)\n",
    "    if (len(pids) == 0):\n",
    "        printD (\"no duplicates left\")\n",
    "    else:\n",
    "        printD(\"duplicates\", pids)\n",
    "        for pid in pids:\n",
    "            printD(pid)\n",
    "            dups = survey[survey.PID==pid]\n",
    "            printD(dups)\n",
    "            for column in dups:\n",
    "                printD(dups[column].values)\n",
    "                try:\n",
    "                    #unique_elements, counts_elements = np.unique(dups[column].values, return_counts=True)\n",
    "                    #print(unique_elements)\n",
    "                    #print(counts_elements)\n",
    "                    unique = np.unique(dups[column].values)\n",
    "                except:\n",
    "                    print(\"couldn't test unique\")\n",
    "                    print(dups[column])\n",
    "                if len(unique)==2:\n",
    "                    printD(\"two the same\")\n",
    "                    printD(column)\n",
    "                    printD(unique) \n",
    "            printD(dups[column])   \n",
    "            \n",
    "# Remove a duplicate row from the survey, identified by ID\n",
    "# pid is the participant id for whom there is a duplicate;\n",
    "# testvar is a variable that can be used to show that there \n",
    "# It is meaningless except to help the writer eyeball things\n",
    "# survey is the survey that has the duplicate.\n",
    "def remove_dup(pid, survey, ID, testvar=''):\n",
    "    \"\"\"Remove a duplicate row from the survey, identified by ID\n",
    "    pid is the participant id for whom there is a duplicate;\n",
    "    testvar is a variable that can be used to show that there \n",
    "    It is meaningless except to help the writer eyeball things\n",
    "    survey is the survey that has the duplicate.\n",
    "    \"\"\"\n",
    "    printD(\"---------------------------------------------\", pid)\n",
    "    dups = survey[survey.PID==pid] if (testvar == '') else survey[survey.PID==pid][testvar] \n",
    "    if len(dups)>1:\n",
    "        dups = survey[survey.PID==pid]\n",
    "        printD(\"number of empty values\", dups.isnull().sum(axis=1).tolist(), dups['PID'].values)\n",
    "        printD (\"checking for id \", ID, \" in data for \", survey[survey.ID==ID]['PID'].values)\n",
    "        if (pid in survey[survey.ID==ID]['PID'].values):\n",
    "            printD(\"removing ID\", ID, \"for\",  survey[survey.ID==ID]['PID'].values)\n",
    "            survey = survey[survey.ID != ID]\n",
    "            dups = survey[survey.PID==pid] if (testvar == '') else survey[survey.PID==pid][testvar] \n",
    "            printD(\"number of dups left for \",pid,\" is: \", len(dups))\n",
    "        else: \n",
    "            printD(\"PID \",pid,\" isn't in \", survey[survey.ID==ID]['PID'].values)\n",
    "    else:\n",
    "        printD(\"no duplicates\",dups)\n",
    "    return survey\n",
    "\n",
    "# Vals is a dictionary of keys (current values) and replacements. All cols in survey\n",
    "# should be searched for those keys and have them replaced with the appropriate values. \n",
    "def cleanup_vals(survey, cols, vals):\n",
    "    \"\"\"Vals is a dictionary of keys (current values) and replacements. All cols in survey\n",
    "       should be searched for those keys and have them replaced with the appropriate values.\"\"\"\n",
    "    for key in vals:\n",
    "        #print(col)\n",
    "        for col in cols:\n",
    "            printD(key)\n",
    "            #if key in survey[col]:\n",
    "            try:\n",
    "                survey[col] = survey[col].replace(key, vals[key])\n",
    "                printD(\"\\'\"+key+\"\\' in \"+col)\n",
    "            except:\n",
    "                printD(\"\\'\"+key+\"\\' not in \"+col)\n",
    "            #for item in survey[col]:\n",
    "            #    print(item, ',', flush=True)\n",
    "            #print('')\n",
    "    return survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning functions for specific Surveys\n",
    "\n",
    "Cleaning has several steps. First we drop rows with too many questions unanswered, which may\n",
    "vary from survey to survey. Then we repair problem data and assign na valuse to empty cells. \n",
    "Finally we find and address duplicate entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     8
    ]
   },
   "outputs": [],
   "source": [
    "def uw_baseline1_specific(survey):\n",
    "    printD(\"uw baseline1 specific\")\n",
    "    printD(survey.columns)\n",
    "    # Bug #1 -- clean up Housing answers, data validation wasn't in place and some were textual\n",
    "    # this helper function converts them to numbers. \n",
    "    printD(\"fixing housing\")\n",
    "    cols = ['Housing_Q2_'+str(i) for i in [1,2,3,4,5]]\n",
    "    cols = cols + ['Housing_Q2', 'Housing_Homenum']\n",
    "    printD(cols)\n",
    "    vals = { \"None\":0, \"None \":0, \"Older Sister, Younger Sister\":2, \"Mom and Dad\":2, \"2 (+1 sibling)\":3, \"80*\":80,\n",
    "       \"80+\":80, \"Roomate\":2, \"Roomate \":2, \"10+\":10, \"Roommate \":2}\n",
    "    survey = cleanup_vals(survey, cols, vals)\n",
    "\n",
    "    # Bug #2 -- We asked twice if people were engineers. We need to merge those columns\n",
    "    # in Baseline1 and Baseline3. Right now, the isengineer function accounts for this.\n",
    "    print(\"XXX TODO Bug in uw_baseline1_specific\")\n",
    "  \n",
    "    # Bug #3 -- remove incorrect entry for PID 141. These were basically the same. Check the excel to see this.\n",
    "    survey = remove_dup(141, survey,  'R_3hF7l4fLFnTwoCS', 'Age')\n",
    "    \n",
    "    survey['LOC']=0\n",
    "\n",
    "    return survey\n",
    "    \n",
    "def uw_baseline2_specific(survey):\n",
    "\n",
    "    # Bug #1 -- we asked twice if people were engineers. We need to merge those columns\n",
    "    # in Baseline2 and Baseline3.  Right now, the isengineer function accounts for this.\n",
    "    # X X TODO\n",
    "    print(\"XXX TODO Bug in uw_baseline2_specific\")\n",
    "\n",
    "    # Bug #2 -- we had no NA for major life events. Some people selected everything. Need to remove answers\n",
    "    # from those people. Right now anyone who answers that 20 things happened in their lifetime \n",
    "    # AND SKIPS NO QUESTIONS is moved over to NAs instead\n",
    "    print(\"cleaning up MLE so we NA bad answers\")\n",
    "    cols = ['MLE_Q1_ChooseMajor','MLE_Q1_ChangeMajor','MLE_Q1_Drop','MLE_Q1_Miss','MLE_Q1_InsDis','MLE_Q1_Cheat',\n",
    "        'MLE_Q1_Workload','MLE_Q1_LowGrades','MLE_Q1_Repeat','MLE_Q1_PartnerProb',\n",
    "        'MLE_Q1_RoommateProb','MLE_Q1_FamilyProb','MLE_Q1_Divorce','MLE_Q1_Illness',\n",
    "        'MLE_Q1_Injury','MLE_Q1_FamilyHealth','MLE_Q1_Pregnant','MLE_Q1_LegalCrisis','MLE_Q1_Income',\n",
    "        'MLE_Q1_Living','MLE_Q1_SeeFamily','MLE_Q1_FriendDie','MLE_Q1_Discrimination','MLE_Q1_Robbery',\n",
    "        'MLE_Q1_Rape','MLE_Q1_SexAssault','MLE_Q1_PhysAbuse','MLE_Q1_KnifeGun','MLE_Q1_EmotAbuse',\n",
    "        'MLE_Q1_ObsAssault','MLE_Q1_FinanceCrisis','MLE_Q1_Horror']\n",
    "    print(\"selecting columns\")\n",
    "    df = survey.loc[:,'MLE_Q1_ChooseMajor':'MLE_Q1_Horror']\n",
    "    nas = {3:-1,0:0,1:1,2:2}\n",
    "    for index, row in df.iterrows():\n",
    "        counts = row.value_counts()\n",
    "        if ((counts.get(3,0) >20) and (counts.get(-1,0) is 0)):\n",
    "            #print(index)\n",
    "            # df.loc[2,'B':'C']=df.loc[2,'B':'C'].map(lambda x: 3)\n",
    "            #print(\"-------- BEFORE ----------\")\n",
    "            #print(baseline2_survey.loc[index, 'MLE_Q1_ChooseMajor_B2':'MLE_Q1_Horror_B2'])\n",
    "            survey.loc[index, 'MLE_Q1_ChooseMajor':'MLE_Q1_Horror']=survey.loc[index, 'MLE_Q1_ChooseMajor':'MLE_Q1_Horror'].map(lambda x: nas[x], na_action = \"ignore\")\n",
    "            #print(\"-------- AFTER ----------\")\n",
    "            #print(baseline2_survey.loc[index, 'MLE_Q1_ChooseMajor_B2':'MLE_Q1_Horror_B2'])\n",
    "\n",
    "    df = survey.loc[:,'MLE_Q1_ChooseMajor':'MLE_Q1_Horror']\n",
    "    #print(df.head())\n",
    "    for index, row in df.iterrows():\n",
    "        counts = row.value_counts()\n",
    "        if ((counts.get(3,0) >20) and (counts.get(-1,0) is 0)):\n",
    "             print(\"index needs updated\")\n",
    "             print(index)\n",
    "             print(counts)\n",
    "             #print(baseline2_survey.loc[index, 'MLE_Q1_ChooseMajor_B2':'MLE_Q1_Horror_B2'])\n",
    "    \n",
    "    # remove the second entry of PID 53. It has a low complete rate (51%)\n",
    "    survey = remove_dup(53, survey,  'R_1M5jbHpWEs6lOap', 'MLE_Q1_Horror')\n",
    "    \n",
    "    # Bug #3 \n",
    "    # will need to clean PSQI_Q2_FALL -- how long does it take you to fall asleep. Sample answers to build a\n",
    "    # solution from: ['5 min', '60 minutes','60+ minutes','15min','15-30','0-10 minutes','&lt;10 min',\n",
    "    #                  '12:00am','10-15 mins','14mim']\n",
    "    print(\"XXX TODO Bug in uw_baseline2_specific\")\n",
    "    \n",
    "\n",
    "    survey['LOC']=0\n",
    "\n",
    "    return survey\n",
    "\n",
    "def uw_mid_specific(survey):\n",
    "    # Bug #1 clean up Housing answers, data validation wasn't in place and some were textual\n",
    "    # this helper function converts them to numbers. \n",
    "    printD(\"cleaning up housing so it is numeric\")\n",
    "    cols = ['Housing_Q2_'+str(i) for i in [1,2,3,4,5]]\n",
    "    cols = cols + ['Housing_Q2','Housing_Homenum']\n",
    "    printD(cols)\n",
    "    vals = {\"None\":0, \"None \":0, \"Older Sister, Younger Sister\":2, \"Mom and Dad\":2, \"2 (+1 sibling)\":3, \"80*\":80,\n",
    "           \"80+\":80, \"Roomate\":2, \"Roomate \":2, \"10+\":10, \"Roommate \":2}\n",
    "    survey = cleanup_vals(survey, cols, vals)\n",
    "    \n",
    "    \n",
    "    # Bug #2 -- we asked twice if people were engineers. We need to merge those columns\n",
    "    # Right now, the isengineer function accounts for this.\n",
    "\n",
    "\n",
    "    # XXX TODO\n",
    "    # will need to clean PSQI_Q2_FALL -- how long does it take you to fall asleep. Sample answers to build a\n",
    "    # solution from: ['5 min', '60 minutes','60+ minutes','15min','15-30','0-10 minutes','&lt;10 min',\n",
    "    #                  '12:00am','10-15 mins','14mim']\n",
    "    print(\"XXX TODO Bug in uw_mid_specific\")\n",
    "\n",
    "\n",
    "    #DUPS: [ 11  15]\n",
    "\n",
    "    # remove incorrect entry for PID 11. They were close to the same.\n",
    "    # one had slightly less detail about major, drinking etc\n",
    "    survey = remove_dup(11, survey,  'R_2wysy4zTpMXrmhc', 'Major_Proposed_TEXT')\n",
    "\n",
    "    # remove incorrect entry for PID 15. They were almost identical\n",
    "    # with one being slightly more complete (I chose that one). Could go the otherway and\n",
    "    # always pick the first one...\n",
    "    survey = remove_dup(15, survey,  'R_1Fggwk8xdyz7dG8', 'Major_Proposed_TEXT')\n",
    "    \n",
    "    # remove the second entry for PID 167. IT has a low complete rate (52%)\n",
    "    survey = remove_dup(167, survey,  'R_d5Sr9qs3KghSS8V', 'Major_Proposed_TEXT')\n",
    "\n",
    "    # remove incorrect entry for PID 63. One was partly filled out, the other\n",
    "    # was complete but had a wrong answer (a time instead of # minutes). \n",
    "    # I hand added in the correct type answer from the deleted entry instead. \n",
    "    #print(baseline3_survey.loc[207, 'PID'])\n",
    "    #survey.loc[survey['ID']=='R_ZgcUPyocJ64o8pP', 'PSQI_Q2_FALL_MID'] = '30'\n",
    "\n",
    "    # remove incorrect entry for PID 167. \n",
    "    #survey = remove_dup(167, survey,  'R_d5Sr9qs3KghSS8V', 'PSQI_Q1_BEDTIME_MID')\n",
    "  \n",
    "    print_diffs(220, survey)\n",
    "    \n",
    "    survey['LOC']=0\n",
    "\n",
    "    return survey\n",
    "\n",
    "def uw_post_specific(survey):\n",
    "    # Fix known bugs in data for Baseline4\n",
    "\n",
    "    # Bug #1 clean up Housing answers, data validation wasn't in place and some were textual\n",
    "    # this helper function converts them to numbers. \n",
    "    print(\"cleaning up housing so it is numeric\")\n",
    "    cols = ['Housing_Q2_'+str(i) for i in [1,2,3,4,5]]\n",
    "    cols = cols + ['Housing_Q2','Housing_Homenum']\n",
    "    print(cols)\n",
    "    vals = {\"None\":0, \"None \":0, \"Older Sister, Younger Sister\":2, \"Mom and Dad\":2, \"2 (+1 sibling)\":3, \"80*\":80,\n",
    "       \"80+\":80, \"Roomate\":2, \"Roomate \":2, \"10+\":10, \"Roommate \":2}\n",
    "    survey = cleanup_vals(survey, cols, vals)\n",
    "\n",
    "    # XXX TODO\n",
    "    # will need to clean PSQI_Q2_FALL -- how long does it take you to fall asleep. Sample answers to build a\n",
    "    # solution from: ['5 min', '60 minutes','60+ minutes','15min','15-30','0-10 minutes','&lt;10 min',\n",
    "    #                  '12:00am','10-15 mins','14mim']\n",
    "    print(\"XXX TODO Bug in uw_post_specific\")\n",
    "    \n",
    "    #set(survey[\"UWEXP_Q4_1_B4\"])\n",
    "\n",
    "    survey['LOC']=0\n",
    "\n",
    "    return survey\n",
    "\n",
    "def uw_discrimination_specific(survey):\n",
    "    survey['LOC_EMA']=0\n",
    "\n",
    "    return survey\n",
    "\n",
    "def cmuII_post_specific(survey):\n",
    "    # duplicates [365 394]\n",
    "    # Answered twice (morning and evening). Took twice is as long the first time; keeping that\n",
    "    survey = remove_dup(365, survey,  'R_7Pq7PhR9acvorCh', 'duration')\n",
    "    # Answered twice, on the 15th and 24th of May. Kept the first one (longer, both were complete)\n",
    "    survey = remove_dup(394, survey, 'R_1gMA2O4n2xe0ri1', 'duration')\n",
    "    \n",
    "    survey['LOC']=1\n",
    "\n",
    "    return survey\n",
    "\n",
    "\n",
    "def cmuII_baseline1_specific(survey):\n",
    "    # duplicates [247]\n",
    "\n",
    "    # One of these two people entered the wrong ID by mistake. Maybe find the ID that is missing?\n",
    "    CMUII_PIDS=[542,250,329,319,312,276,281,538,489,507,283,365,378,278,245,365,607,302,476,208,268,410,485,397,271,474,237,254,251,665,500,247,361,551,233,318,555,212,303,671,518,294,451,672,427,284,477,460,415,417,209,338,218,577,360,422,343,402,523,240,339,248,479,609,291,393,255,413,369,430,512,210,379,492,559,581,331,337,398,595,454,342,333,465,336,431,226,525,321,322,457,362,563,267,483,257,256,332,300,394,662,239,304,374,461,450,444,205,203,409,522,228,435,350,293,244,308,274,260,414,528,275,539,515,373,269,264,285,452,213,463,298,376,330,263,541,445,217,202,644,615,380,246,231,344,424,207,390,290,292,326,386,270,201,230,532,266,309,453,306,510,262,659,491,617,229,242,693,613,497,297,629,214,664,706,531,243,714,234,252,395,572,653,711,327,279,220,438,282,383,462,261,396,381,272,215,655,200,211,669,355,311,363,670,235,359,206,334,259,631,204,241,394,473,466,368,295,412,289,305,432,472,540,434,506,277,307,352,487,513,236,586,419,668,301,416,224,514,401,686,517,315,314]\n",
    "    survey_PIDS=survey['PID']\n",
    "    #print(\"possible indexes that \")\n",
    "    #print(survey_PIDS)\n",
    "    #print(CMUII_PIDS)\n",
    "    print(np.setdiff1d(CMUII_PIDS, survey_PIDS))\n",
    "    \n",
    "    # removing both for now. don't know which is right...\n",
    "    #survey = remove_dup(236, survey,  'R_O3dSSLF1JQtH0Yh', 'Housing_Q1')\n",
    "    survey = remove_dup(247, survey,  'R_1NbkalYT58DZhCQ', 'Housing_Q1')\n",
    "    \n",
    "    survey['LOC']=1\n",
    "\n",
    "    return survey\n",
    "\n",
    "def cmuII_baseline2_specific(survey):\n",
    "    # duplicates [236 259 326 328]\n",
    "\n",
    "    # This survey was less complete\n",
    "    survey = remove_dup(236, survey,  'R_1g5sTRUNrZp7xKe', 'duration')\n",
    "    # This survey was less complete\n",
    "    survey = remove_dup(259, survey,  'R_2tEx8tnHygzVmTV', 'duration')\n",
    "    # was totally incomplete\n",
    "    survey = remove_dup(326, survey,  'R_1dF9iqQ9TWM4Exf', 'duration')\n",
    "    # was much les complete. Big thing it had was MLEs that were not originally reported. Consider merging?\n",
    "    survey = remove_dup(328, survey,  'R_bjbilLmmRd1AWop', 'duration')\n",
    "\n",
    "    survey['LOC']=1\n",
    "\n",
    "    return survey\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions for Creating Scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scales(config, dataconfig, surveys):\n",
    "    configdir = config[\"configdir\"]\n",
    "    survey_names = dataconfig[\"surveys\"]\n",
    "    \n",
    "    # Load the json file that has the scale info in it\n",
    "    with open(configdir+dataconfig[\"scaleconfig\"], 'r') as file_obj:\n",
    "        scaleconfig = json.load(file_obj)\n",
    "        file_obj.close()\n",
    "            \n",
    "    scales = scaleconfig[\"scales\"]\n",
    "    functions = scaleconfig[\"scale_functions\"]\n",
    "    # additional markers for some complex scales that needs some aggregation between several columns\n",
    "    # it is a dict with {key: the complex scales name, value: the corresponding function to calculate the score}\n",
    "    # This flag will keep passing down to later functions until when the real calculation is going to happen\n",
    "    # i.e., in the \"calculate_scale\" function.\n",
    "    aggfunc_flags = scaleconfig[\"scale_aggfunc_flag\"] \n",
    "    for scale, function in functions.items():\n",
    "        functions[scale] = eval(function)\n",
    "#     try:\n",
    "#         aggfunc_flags = eval(aggfunc_flags)\n",
    "#     except:\n",
    "#         pass\n",
    "    \n",
    "    for survey in survey_names:\n",
    "        print(\"calculating scales for \", survey)\n",
    "        name = dataconfig[survey][\"name\"]\n",
    "        surveys[survey] = calculate_scales(scales, functions, aggfunc_flags, surveys[survey], name)\n",
    "#         display(HTML(surveys[survey].head(n=50).to_html()))\n",
    "\n",
    "    # XXX TODO check if we should add any of the baseline1 scales to Baseline4 before we run it. \n",
    "    #(BFI, MFQ, SES)\n",
    "    \n",
    "    return surveys\n",
    "\n",
    "#  Calculates many scales by looping through them all and running \n",
    "#  any that are valid for this data set\n",
    "def calculate_scales(scales, scale_functions, aggfunc_flags, df, survey_id): \n",
    "    ''' Calculates many scales by looping through them all and running \n",
    "    any that are valid for this data set'''\n",
    "    for name, items in scales.items():\n",
    "        fun = scale_functions.get(name, scale_functions.get('Default'))\n",
    "        # the value is got from the aggfunc_flags\n",
    "        # if it is a zero, it means it is a simple scale and no need to do cross-column calculation\n",
    "        # if it is not a zero, it means that it has a function to calculate this scale.\n",
    "        # the flag won't take effect until it is passed into the calculate_scale function.\n",
    "        flag = aggfunc_flags.get(name, aggfunc_flags.get('Default'))\n",
    "        print(\"function is: \", fun)\n",
    "        print(\"aff fun is: \", flag)\n",
    "        print(\"scale is: \", name)\n",
    "        printD(\"Name is: \", name)\n",
    "        printD(\"items are: \", items)\n",
    "        \n",
    "        # since ALL will only happen if using a merging_by_column method.\n",
    "        # this line should be able to work only when merging by cols\n",
    "        if (survey_id == \"ALL\"):\n",
    "            name = name + \"_\" + str(survey_id)\n",
    "            \n",
    "        if name not in df.columns:\n",
    "            printD(\"calculating scale\")\n",
    "            #try:\n",
    "            res = calculate_scale(fun, flag, items, df, name, survey_id)\n",
    "            df = res\n",
    "            #except:\n",
    "            #    print(\"scale is: \", name)\n",
    "            #    print(\"Name is: \", name)\n",
    "            #    print(\"scale failed: \", name)\n",
    "        else:\n",
    "            print(name, \"already have, no calculation\")\n",
    "        print(\"Survey size: \", df.shape)\n",
    "    return df\n",
    "\n",
    "# The user can pass in a function for summarizing data across columns\n",
    "# and this will calculate a result. \n",
    "# summary_fun is a function that takes as input the current summary scores for a particular\n",
    "#              scale, the scores for the current item of that scale, and the total number of items\n",
    "# aggfunc_flag is an additional dict for complex cross-columns calculation\n",
    "# scale_name is the name of the scale (to be looked up in global variable scales) TODO pass this in?\n",
    "# survey_results is a set of survey results over which to calculate the score\n",
    "# result_name is the name that the final summary for the scale should be given\n",
    "# survey_id is which survey (e.g. B1 for baseline 1)\n",
    "# normalize is whether to normalize on a 0-1 basis after calculating\n",
    "# Returns a DataFrame containing the entire survey passed in, with the new column added (named result_name) \n",
    "def calculate_scale(summary_fun, aggfunc_flag, scale_items, survey, result_name, survey_id, normalize=False):\n",
    "    scores = pd.Series(np.zeros(survey.shape[0]), index=survey.index, name=result_name)\n",
    "    if (scale_items[0] not in survey.columns):\n",
    "        print(scale_items[0] + \" not in columns\")\n",
    "        return survey\n",
    "    \n",
    "    # the place where the flag take effect\n",
    "    # if the flag is zero, then it is a simple scale calculation, scores can be calculated column by column indenpendently\n",
    "    # otherwise it will run a function that do complex calculation across the columns\n",
    "    if (str(aggfunc_flag) == \"0\"):\n",
    "        print(\"calculating: \" , result_name)\n",
    "        printD(scale_items)\n",
    "        for item_name in scale_items: \n",
    "    #         if (survey_id != \"ALL\"): item_name = item_name+\"_\"+survey_id\n",
    "            if (item_name not in survey.columns):\n",
    "                print(item_name + \" not in columns\")\n",
    "#                 return survey\n",
    "                continue\n",
    "            newitem = survey.loc[:,item_name]\n",
    "            scores = summary_fun(scores,newitem,item_name,len(scale_items))\n",
    "            printD(\"item is: \", item_name)\n",
    "            printD(newitem.value_counts())\n",
    "    else:\n",
    "        scores = eval(aggfunc_flag)(scores, survey, scale_items)\n",
    "    printD(\"adding\",result_name,result_name,pd.Series(scores).value_counts())\n",
    "    if (normalize):\n",
    "        maxx = scores.max()\n",
    "        scores = scores.apply(lambda x: x/maxx)\n",
    "    survey = pd.concat((survey, scores.rename(result_name)), axis=1)\n",
    "    printD(survey.head())\n",
    "\n",
    "        \n",
    "    return survey\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for scale (column-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A number of different summary function for different scales\n",
    "\n",
    "# For scales that aren't defined yet, just return the values of the scores\n",
    "# for the last item in the scale\n",
    "def noop(scores, newitem, item_name, num_scale_items):\n",
    "    printD(item_name, \" is not yet defined as a scale\")\n",
    "    return scores\n",
    "\n",
    "# calculates the mean across all items\n",
    "# expects as input a Series of scores (to be incrementally added to), the newitem (to add in), the item name, \n",
    "# and the number of total items in the scale being summarized\n",
    "def summary_mean(scores, newitem, item_name, num_scale_items):\n",
    "    # XXX TODO double check with daniela's code what to do with missing values\n",
    "    print(\"XXX TODO for mean score calculation\")\n",
    "    newitem = newitem.apply(lambda x: 0 if (x<0) else x)\n",
    "\n",
    "    scores = scores.add(newitem/num_scale_items,fill_value = 0)\n",
    "    return scores\n",
    "\n",
    "# adds together the scores on all the scale items\n",
    "def summary_sum(scores, newitem, item_name, num_scale_items):\n",
    "    newitem = newitem.apply(lambda x: 0 if (x<0) else x)\n",
    "\n",
    "    scores = scores.add(newitem,fill_value = 0)\n",
    "    scores = scores.apply(lambda x: -1 if (x<=-1) else x)\n",
    "\n",
    "    return scores\n",
    "\n",
    "# Combines scale items from different phases/locations (should have no overlap)\n",
    "def summary_sum_merge(scores, newitem, item_name, num_scale_items):\n",
    "    print(item_name)\n",
    "    print(\"values for\", item_name, pd.Series(newitem).value_counts())\n",
    "\n",
    "    # Scores are initialized to all 0s. So: if this is the first one we've seen, just use it\n",
    "    if (max(scores) == 0):\n",
    "       return newitem\n",
    "    \n",
    "    scores = scores.add(newitem,fill_value = 0)\n",
    "    \n",
    "    print(pd.Series(scores).value_counts())\n",
    "    return scores\n",
    "    \n",
    "# when merging, a scale will have unknowns for all PIDs who weren't in that location\n",
    "# def pick_valid(x, y): \n",
    "#     printD(\"x: \", x, \"y: \", y)\n",
    "#     if ((x is None or x<=-1) and (y is None or y<=-1)):\n",
    "#         return -1\n",
    "#     elif (y is None or y <=-1):\n",
    "#         return x\n",
    "#     elif (x is None or x <=-1):\n",
    "#         return y\n",
    "#     else:\n",
    "#         return x + y\n",
    "\n",
    "# adds together the scores on all the scale items that have 1 \n",
    "def binary_sum(scores, newitem, item_name, num_scale_items):\n",
    "    newitem = newitem.apply(lambda x: 0 if (x<0) else x)\n",
    "\n",
    "    scores = scores.add(newitem,fill_value = 0)\n",
    "    scores = scores.apply(lambda x: 1 if (x>=1) else 0)\n",
    "    return scores\n",
    "    \n",
    "    \n",
    "def BDI_Correct_range(scores, newitem, item_name, num_scale_items):\n",
    "    # CMU seems to have their data with values 5 and higher instead of 1 and higher\n",
    "    # 21-items \n",
    "    # Scaling 0-3\n",
    "    print(\"Calculating BDI Scale \", item_name)\n",
    "    print(\"min: \",min(newitem),\" max: \",max(newitem))   \n",
    "    print(pd.Series(newitem).value_counts())\n",
    "\n",
    "    rescale = {8: 3, 7:2, 5:0, 6:1}\n",
    "        \n",
    "    if (\"Pessimism\" in item_name):\n",
    "        rescale = {7: 3, 6:2, 5:0, 4:1}\n",
    "    elif (\"Failure\" in item_name):\n",
    "        rescale = {8: 3, 6:2, 5:0, 4:1}\n",
    "    elif (\"Suicid\" in item_name):\n",
    "        rescale = {9: 3, 8:2, 5:0, 6:1}\n",
    "    elif ((\"Sleep\" in item_name) or\n",
    "          (\"Appetite\" in item_name)):\n",
    "        if(max(newitem) == 7):\n",
    "            rescale = {1:0, 2:1,3:2, 4:3,5:4,6:5,7:6}\n",
    "        elif(max(newitem) == 11):\n",
    "            rescale = {5:0, 6:1,7:2, 8:3,9:4,10:5,11:6}\n",
    "    \n",
    "    if max(newitem) > 6 : # need to rescale scores significantly\n",
    "        newitem = newitem.map(lambda x: rescale.get(x,0))\n",
    "    elif (min(newitem) == 1 or max(newitem) == 4): # need to map from 4,3,2,1 to 3,2,1,0\n",
    "        newitem = newitem.add(-1,fill_value = 0)\n",
    "    \n",
    "    print(\"min: \",min(newitem),\" max: \",max(newitem))   \n",
    "    \n",
    "    # Scores are initialized to all 0s. So: if this is the first one we've seen, just use it\n",
    "    print(\"newitem\",pd.Series(newitem).value_counts())\n",
    "    print(\"scores\",pd.Series(newitem).value_counts())\n",
    "\n",
    "    if (max(scores) == 0):\n",
    "        scores = newitem\n",
    "    else: \n",
    "        scores = scores.add(newitem,fill_value = 0)\n",
    "    \n",
    "    return scores\n",
    "  \n",
    "def mean_with_reversals(scores, newitem, item_name, reverse_list, reverse_max, num_items):\n",
    "    newitem = newitem.apply(lambda x: 0 if (x<0) else x)\n",
    "    if (item_name in reverse_list): \n",
    "        printD(newitem)\n",
    "        newitem = -1 * newitem.subtract(reverse_max,fill_value = 0) #XXXX NEED TO MAKE SURE 1-4 is correct here\n",
    "        printD(newitem)\n",
    "    scores = scores.add(newitem/num_items,fill_value = 0)\n",
    "    return scores\n",
    "\n",
    "def sum_with_reversals(scores, newitem, item_name, reverse_list, reverse_max):\n",
    "    newitem = newitem.apply(lambda x: 0 if (x<0) else x)\n",
    "    if (item_name in reverse_list): \n",
    "        printD(newitem)\n",
    "        newitem = -1 * newitem.subtract(reverse_max,fill_value = 0) #XXXX NEED TO MAKE SURE 1-4 is correct here\n",
    "        printD(newitem)\n",
    "    scores = scores.add(newitem,fill_value = 0)\n",
    "    return scores\n",
    "\n",
    "\n",
    "# adds together the scores on all the scale items. Reverses correct scales\n",
    "def cesd(scores, newitem, item_name, num_scale_items):\n",
    "    # 0 1 2 3 : 'CES_D_1','CES_D_2','CES_D_3', 'CES_D_5','CES_D_6','CES_D_7','CED_S_9','CED_S_10','CES_D_11',\n",
    "    #           'CES_D_13','CES_D_14','CES_D_15', 'CES_D_17','CES_D_18','CES_D_19','CES_D_20'],\n",
    "    # 3 2 1 0 : 'CES_D_4', 'CES_D_8','CES_D_12','CES_D_16',\n",
    "    # These scale items need to be reversed\n",
    "    print(\"cesd bug: currently not checking number of missing items. Should only allow 4\")\n",
    "    print(\"min: \",min(newitem),\" max: \",max(newitem))   \n",
    "\n",
    "    reverse = [\"CES_D_4\",\"CES_D_8\",\"CES_D_12\",\"CES_D_16\"]\n",
    "#     if (min(newitem) == 1 or max(newitem) == 4):\n",
    "#         newitem = newitem.subtract(1,fill_value = 0)\n",
    "  \n",
    "    print(\"min: \",min(newitem),\" max: \",max(newitem))   \n",
    "    \n",
    "    scores = sum_with_reversals(scores, newitem, item_name, reverse, 3)\n",
    "    print(pd.Series(newitem).value_counts())\n",
    "    return scores\n",
    "\n",
    "def bfi(scores, newitem, item_name, num_scale_items):\n",
    "    reverse = [\"BFI_10_1\",\"BFI_10_3\",\"BFI_10_4\",\"BFI_10_5\",\"BFI_10_7\"]\n",
    "    scores = sum_with_reversals(scores, newitem, item_name, reverse, 6)\n",
    "    \n",
    "    print(\"min: \",min(newitem),\" max: \",max(newitem))  \n",
    "    print(pd.Series(newitem).value_counts())\n",
    "    return scores\n",
    "\n",
    "# adds together the scores on all the scale items. Reverses correct scales\n",
    "def ucla(scores, newitem, item_name, num_scale_items):\n",
    "    printD(item_name)\n",
    "     # Comment UCLA loneliness Scale (ULCA_LS)\n",
    "     # Total number of items: 20\n",
    "     # Scale 1 - never to 4 - always \n",
    "     # The total score is calculated by finding the sum of 20 items\n",
    "     # Range: 0 to 80 - higher score indicating more loneliness\n",
    "    # Items #1,5,6,9,10,15,16,19,20 are reversed scored\n",
    "    \n",
    "    reverse = ['UCLA_Q1_1','UCLA_Q1_5','UCLA_Q1_6','UCLA_Q1_9','UCLA_Q1_10','UCLA_Q2_5','UCLA_Q2_6','UCLA_Q2_9','UCLA_Q2_10']\n",
    "    # These scale items need to be reversed\n",
    "    print(\"min: \",min(newitem),\" max: \",max(newitem))     \n",
    "    scores = sum_with_reversals(scores, newitem, item_name, reverse, 5)\n",
    "    print(pd.Series(newitem).value_counts())\n",
    "    return scores\n",
    "\n",
    "# adds together the scores on all the scale items. Reverses correct scales\n",
    "def isel(scores, newitem, item_name, num_scale_items):\n",
    "    print(item_name)\n",
    "     # Number of items - 12\n",
    "     # scaling 1-4\n",
    "     # To score, sum across all items (reverse- code items 1, 2, 7, 8, 11, 12)\n",
    "     # Appraisal: item numbers 2, 4, 6, 11\n",
    "     # Belonging: item numbers 1, 5, 7, 9\n",
    "     # Tangible: item numbers 3, 8, 10, 12\n",
    "\n",
    "\n",
    "#     rescale = {8: 3, 7:2, 6:1, 5:0}\n",
    "        \n",
    "#     if max(newitem) == 8 : # need to rescale scores significantly\n",
    "#         newitem = newitem.map(lambda x: rescale.get(x,0))\n",
    "        \n",
    "    reverse = ['KISEL_12_1','KISEL_12_2','KISEL_12_7','KISEL_12_8','KISEL_12_11','KISEL_12_12']\n",
    "    # These scale items need to be reversed\n",
    "    print(\"min: \",min(newitem),\" max: \",max(newitem))     \n",
    "    scores = sum_with_reversals(scores, newitem, item_name, reverse, 5)\n",
    "    print(pd.Series(newitem).value_counts())\n",
    "    return scores\n",
    "\n",
    "# This is wrong. Replaced with summary_sum in input files\n",
    "# https://www.ocf.berkeley.edu/~johnlab/pdfs/ERQ.pdf says\n",
    "# Scoring (no reversals)\n",
    "# Reappraisal Items: 1, 3, 5, 7, 8, 10; Suppression Items: 2, 4, 6, 9. \n",
    "def rq(scores, newitem, item_name, num_scale_items):\n",
    "    print(\"XXXX WRONG should use summary-sum\")\n",
    "    reverse = [\"RQ_1\",\"RQ_2\",\"RQ_3\",\"RQ_4\",\"RQ_5\",\"RQ_6\",\"RQ_9\",\"RQ_11\",\"RQ_12\",\"RQ_13\"]\n",
    "    scores = sum_with_reversals(scores, newitem, item_name, reverse, 8)\n",
    "    return scores\n",
    "\n",
    "def stai(scores, newitem, item_name, num_scale_items):\n",
    "    reverse = [\"STAI_\" + str(i) for i in  [1,2,5,8,10,11,15,16,19,20]]\n",
    "    scores = sum_with_reversals(scores, newitem, item_name, reverse, 5)\n",
    "    return scores\n",
    "\n",
    "def ffmq_cmu(scores, newitem, item_name, num_scale_items):\n",
    "    reverse = [\"FFMQ_\" + str(i) for i in  [4,5,7,8,11,12,14,17,19,22,23,24]]\n",
    "    scores = sum_with_reversals(scores, newitem, item_name, reverse, 6)\n",
    "    return scores\n",
    "\n",
    "def lotr(scores, newitem, item_name, num_scale_items):\n",
    "    reverse = [\"LOTR_\" + str(i) for i in  [2,4,6]]\n",
    "    scores = sum_with_reversals(scores, newitem, item_name, reverse, 6)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def let(scores, newitem, item_name, num_scale_items):\n",
    "    reverse = [\"LOTR_\" + str(i) for i in  [7,9,16]]\n",
    "    scores = sum_with_reversals(scores, newitem, item_name, reverse, 6)\n",
    "    return scores\n",
    "\n",
    "# adds together the scores on all the scale items. Reverses correct scales\n",
    "def pss(scores, newitem, item_name, num_scale_items):\n",
    "   # PSS-10 scores are obtained by reversing the scores on the four positive items, e.g., 0=4, 1=3, 2=2, etc. \n",
    "   # and then summing across all 10 items.  \n",
    "   # Items 4,5, 7, and  8 are the positively stated items so they need to be reversed scored \n",
    "    reverse = ['KPSS_4','KPSS_5','KPSS_7','KPSS_8']\n",
    "#     if (min(newitem) == 1 or max(newitem) == 5):\n",
    "#         newitem = newitem.subtract(1,fill_value = 0) # correct for UW data\n",
    "    print(\"min: \",min(newitem),\" max: \",max(newitem))     \n",
    "    scores = sum_with_reversals(scores, newitem, item_name, reverse, 4)\n",
    "    print(pd.Series(newitem).value_counts())\n",
    "    return scores\n",
    "\n",
    "def ptec(scores, newitem, item_name, num_scale_items):\n",
    "   # PSS-10 scores are obtained by reversing the scores on the four positive items, e.g., 0=4, 1=3, 2=2, etc. \n",
    "   # and then summing across all 10 items.  \n",
    "   # Items 4,5, 7, and  8 are the positively stated items so they need to be reversed scored \n",
    "    reverse = ['PTEC5','PTEC9','PTEC12','PTEC13']\n",
    "#     if (min(newitem) == 1 or max(newitem) == 5):\n",
    "#         newitem = newitem.subtract(1,fill_value = 0) # correct for UW data\n",
    "    print(\"min: \",min(newitem),\" max: \",max(newitem))     \n",
    "    scores = sum_with_reversals(scores, newitem, item_name, reverse, 4)\n",
    "    print(pd.Series(newitem).value_counts())\n",
    "    return scores\n",
    "\n",
    "def rrq(scores, newitem, item_name, num_scale_items):\n",
    "   # PSS-10 scores are obtained by reversing the scores on the four positive items, e.g., 0=4, 1=3, 2=2, etc. \n",
    "   # and then summing across all 10 items.  \n",
    "   # Items 4,5, 7, and  8 are the positively stated items so they need to be reversed scored \n",
    "    reverse = ['RRQ_6','RRQ_9','RRQ_10','RRQ_13','RRQ_14','RRQ_17','RRQ_20','RRQ_24']\n",
    "#     if (min(newitem) == 1 or max(newitem) == 5):\n",
    "#         newitem = newitem.subtract(1,fill_value = 0) # correct for UW data\n",
    "    print(\"min: \",min(newitem),\" max: \",max(newitem))     \n",
    "    scores = sum_with_reversals(scores, newitem, item_name, reverse, 6)\n",
    "    print(pd.Series(newitem).value_counts())\n",
    "    return scores\n",
    "\n",
    "def sf12(scores, newitem, item_name, num_scale_items):\n",
    "    # Items SF_12_Q1, SF_12_Q5 are reversed in 1 - 5\n",
    "    # Items SF_12_Q6_1, SF_12_Q6_2 are reversed in 1 - 6\n",
    "    # Scores are 12 - 47\n",
    "    # true algorithm is not available\n",
    "    rev5 = [\"SF_12_Q1\", \"SF_12_Q5\"]\n",
    "    rev6 = [\"SF_12_Q6_1\", \"SF_12_Q6_2\"]\n",
    "    if (item_name in rev5):\n",
    "        newitem = -1 * newitem.subtract(6, fill_value = 0)\n",
    "    elif (item_name in rev6):\n",
    "        newitem = -1 * newitem.subtract(7, fill_value = 0)\n",
    "    scores = scores.add(newitem, fill_value = 0)\n",
    "    return scores\n",
    "    \n",
    "def brs(scores, newitem, item_name, num_scale_items):\n",
    "    # Brief Resilience Scale \n",
    "    # 6-items \n",
    "    # Reverse Scored items: 2, 4, 6 \n",
    "    reverse = ['BRS_2','BRS_4','BRS_6']\n",
    "    print(\"min: \",min(newitem),\" max: \",max(newitem))     \n",
    "    scores = mean_with_reversals(scores, newitem, item_name, reverse, 6, num_scale_items)\n",
    "    print(pd.Series(newitem).value_counts())\n",
    "    return scores\n",
    "\n",
    "def sss(scores, newitem, item_name, num_scale_items):\n",
    "    # - 2-way social support scale \n",
    "    # 21 items\n",
    "    # Scale: 0 - not at all to 5 - always \n",
    "    # Subscales:\n",
    "    #  Receiving emotional support: 1, 4, 6, 10, 16, 18, \n",
    "    #  Giving emotional support: 3, 7, 14, 19, 21\n",
    "    #  Receiving instrumental support: 5, 8, 11, 15\n",
    "    #  Giving instrumental support: 2, 9, 12, 17, 20\n",
    "    #  Receiving support (instrumental + emotional) \n",
    "    # Giving support (instrumental + emotional) \n",
    "    print(\"min: \",min(newitem),\" max: \",max(newitem))     \n",
    "    print(pd.Series(newitem).value_counts())\n",
    "    newitem = newitem.apply(lambda x: 0 if (x<=-1) else x)\n",
    "    scores = scores.add(newitem,fill_value = 0)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def erq(scores, newitem, item_name, num_scale_items):\n",
    "    # Should be a straight sum, but qualtrics had the items\n",
    "    # reversed of what they should be scored. Needs to be\n",
    "    # checked on cmu XXXX\n",
    "    print(\"XXXXX need to double check in CMU data\")\n",
    "    print(\"min: \",min(newitem),\" max: \",max(newitem))     \n",
    "    print(pd.Series(newitem).value_counts())\n",
    "    newitem = newitem.apply(lambda x: 0 if (x<=-1) else 8-x)\n",
    "    scores = scores.add(newitem,fill_value = 0)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def gmm(scores, newitem, item_name, num_scale_items):\n",
    "    # Mean all items. \n",
    "    # XXXXX ERROR IN UW AND CMU DATA: Max is 7, so subtract from 8 to reverse\n",
    "    print(num_scale_items)\n",
    "    print(\"min: \",min(newitem),\" max: \",max(newitem))     \n",
    "    print(pd.Series(newitem).value_counts())\n",
    "    newitem = newitem.apply(lambda x: 0 if (x<=-1) else (8-x)/num_scale_items)\n",
    "    scores = scores.add(newitem,fill_value = 0)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "# calculates the number of items reporting an event this year or this quarter\n",
    "def mle_thisyear(scores, newitem, item_name, num_scale_items): \n",
    "    newitem = newitem.apply(lambda x: 0 if (x<0) else x)\n",
    "\n",
    "    scores = scores.add(newitem.apply(lambda x: 1 if(x<=2) else 0),fill_value=0)\n",
    "    scores = scores.apply(lambda x: 1 if (x>=1) else 0)\n",
    "    return scores\n",
    "\n",
    "# calculates the number of items reporting an event this quarter\n",
    "def mle_thisquarter(scores, newitem, item_name, num_scale_items):\n",
    "    newitem = newitem.apply(lambda x: 0 if (x<0) else x)\n",
    "\n",
    "    # in Baseline 4 we changed the question to only ask about the last quarter, thus it \n",
    "    printD(\"ml this quarter\")\n",
    "    printD(item_name)\n",
    "    #print(newitem.apply(lambda x: 1 if (x == 1) else 0))\n",
    "    scores = scores.add(newitem.apply(lambda x: 1 if(x == 1) else 0),fill_value=0)     \n",
    "    scores = scores.apply(lambda x: 1 if (x>=1) else 0)\n",
    "    return scores\n",
    "\n",
    "def mle_count(scores, newitem, item_name, num_scale_items):\n",
    "    newitem = newitem.apply(lambda x: 0 if (x<0) else x)\n",
    "\n",
    "    # in Baseline 4 we changed the question to only ask about the last quarter, thus it \n",
    "    printD(\"ml this quarter\")\n",
    "    printD(item_name)\n",
    "    #print(newitem.apply(lambda x: 1 if (x == 1) else 0))\n",
    "    scores = scores.add(newitem.apply(lambda x: 1 if (x == 1) else 0),fill_value=0)     \n",
    "    return scores\n",
    "    \n",
    "# returns a 1 if anything matches engineering intent, and 0 otherwise\n",
    "def isengineer(scores, newitem, item_name, num_scale_items):\n",
    "    printD(\"isengineer\")\n",
    "    if (\"ngineer\" in item_name):\n",
    "        scores = scores.add(newitem,fill_value=0)\n",
    "    elif (\"TEXT\" in item_name):\n",
    "        newitem = newitem.astype(str)\n",
    "        newitem = newitem.apply(lambda x: 1 if ((\"engineer\" in x) or (\"omputer\" in x)) else 0)\n",
    "        scores = scores.add(newitem,fill_value=0)\n",
    "    printD(\"making binary\")\n",
    "    scores = scores.apply(lambda x: 1 if(x>=1) else 0)\n",
    "    return scores\n",
    "\n",
    "def isartsci(scores, newitem, item_name, num_scale_items):\n",
    "    printD(\"isartsci\")\n",
    "    if (\"AS\" in item_name):\n",
    "        scores = scores.add(newitem,fill_value=0)\n",
    "#     elif (\"TEXT\" in item_name):\n",
    "#         newitem = newitem.astype(str)\n",
    "#         newitem = newitem.apply(lambda x: 1 if ((\"art\" in x.lower()) or (\"science\" in x.lower())) else 0)\n",
    "#         scores = scores.add(newitem,fill_value=0)\n",
    "    printD(\"making binary\")\n",
    "    scores = scores.apply(lambda x: 1 if(x>=1) else 0)\n",
    "    return scores\n",
    "\n",
    "def isbusiness(scores, newitem, item_name, num_scale_items):\n",
    "    printD(\"isbusiness\")\n",
    "    if (\"siness\" in item_name):\n",
    "        scores = scores.add(newitem,fill_value=0)\n",
    "#     elif (\"TEXT\" in item_name):\n",
    "#         newitem = newitem.astype(str)\n",
    "#         newitem = newitem.apply(lambda x: 1 if (\"siness\" in x.lower()) else 0)\n",
    "#         scores = scores.add(newitem,fill_value=0)\n",
    "    printD(\"making binary\")\n",
    "    scores = scores.apply(lambda x: 1 if(x>=1) else 0)\n",
    "    return scores\n",
    "\n",
    "def iscse(scores, newitem, item_name, num_scale_items):\n",
    "    printD(\"iscse\")\n",
    "    newitem = newitem.astype(str)\n",
    "    newitem = newitem.apply(lambda x: 1 if ((\"omputer\" in x)) else 0)\n",
    "    scores = scores.add(newitem,fill_value=0)\n",
    "    printD(\"making binary\")\n",
    "    scores = scores.apply(lambda x: 1 if(x>=1) else 0)\n",
    "    return scores\n",
    "\n",
    "# This is adjusted in 'scales' and  here\n",
    "# returns a 1 if anything matches minority, and 0 otherwise\n",
    "def isurm(scores, newitem, item_name, num_scale_items):\n",
    "    if ((\"frican\" in item_name) or (\"Latin\" in item_name) or (\"Islander\" in item_name) or (\"Native\" in item_name)):\n",
    "        scores = scores.add(newitem.apply(lambda x: 1 if(x==1) else 0),fill_value=0)\n",
    "    elif (\"TEXT\" in item_name):\n",
    "        scores = scores.add(newitem.apply(lambda x: 1 if (\"racial\" in str(x)) else 0),fill_value=0)\n",
    "    scores = scores.apply(lambda x: 1 if(x>=1) else 0)\n",
    "    return scores\n",
    "\n",
    "# This is adjusted in 'scales' and  here\n",
    "# returns a 1 if anything matches minority, and 0 otherwise\n",
    "def isminority(scores, newitem, item_name, num_scale_items):\n",
    "    if ((\"Asian\" in item_name) or (\"frican\" in item_name) or (\"Latin\" in item_name) or (\"Islander\" in item_name) or (\"Native\" in item_name)):\n",
    "        scores = scores.add(newitem.apply(lambda x: 1 if(x==1) else 0),fill_value=0)\n",
    "    elif (\"TEXT\" in item_name):\n",
    "        scores = scores.add(newitem.apply(lambda x: 1 if (\"racial\" in str(x)) else 0),fill_value=0)\n",
    "    scores = scores.apply(lambda x: 1 if(x>=1) else 0)\n",
    "    return scores\n",
    "\n",
    "# This is adjusted in 'scales' and  here\n",
    "# returns a 1 if anything matches minority, and 0 otherwise\n",
    "def isminorityfirstgen(scores, newitem, item_name, num_scale_items):\n",
    "    printD(item_name)\n",
    "    if ((\"Minority\" in item_name) or (\"Latin\" in item_name) or (\"Islander\" in item_name) or (\"Native\" in item_name)):\n",
    "        scores = scores.add(newitem.apply(lambda x: 1 if(x==1) else 0),fill_value=0)\n",
    "    elif (\"TEXT\" in item_name):\n",
    "        scores = scores.add(newitem.apply(lambda x: 1 if (\"racial\" in x) else 0),fill_value=0)\n",
    "    if (\"Firstgen\" in item_name):\n",
    "        scores = newitem.apply(lambda x: 1 if(x==1) else 0)\n",
    "        \n",
    "    scores = scores.apply(lambda x: 1 if(x>=1) else 0)\n",
    "    return scores\n",
    "\n",
    "def sexuality(scores, newitem, item_name, num_scale_items):\n",
    "    printD(item_name)\n",
    "\n",
    "    scores = scores.add(newitem.apply(lambda x: 1 if (x>=3) else 0),fill_value=0)\n",
    "    scores = scores.apply(lambda x: 1 if(x>=1) else 0)\n",
    "    return scores\n",
    "\n",
    "# counts everyone who is a first generation student\n",
    "def isfirstgen(scores, newitem, item_name, num_scale_items):\n",
    "    printD(item_name)\n",
    "    # if scores are all zeros turn to 1 because we will\n",
    "    # either replace scores or multiply against them\n",
    "    if (not scores.sum()):\n",
    "        scores = scores.apply(lambda x: 1)\n",
    "        \n",
    "    # self reported first gen status\n",
    "    if (\"Firstgen\" in item_name):\n",
    "        scores = newitem.apply(lambda x: 0 if(x==1) else 1)\n",
    "    # first gen status based on parent\n",
    "    if ((\"mother\" in item_name) or (\"father\" in item_name)):\n",
    "        printD(\"parent is firstgen\")\n",
    "        printD(newitem)\n",
    "        scores = scores * newitem.apply(lambda x: 0 if (x > 3 or x < 0) else 1)\n",
    "        \n",
    "    printD(scores)\n",
    "    return scores\n",
    "\n",
    " \n",
    "# adjust scoring for employment so that 0 = not employed, 1 = part time and 2 = fulltime\n",
    "def employment(scores, newitem, item_name, num_scale_items):\n",
    "    # XXX TODO double check with daniela's code what to do with missing values\n",
    "    print(\"XXX TODO for employment score calculation\")\n",
    "    newitem = newitem.apply(lambda x: -1 if (x<0) else x)\n",
    "\n",
    "    scores = newitem.add(-1,fill_value = 0)\n",
    "    return scores\n",
    "\n",
    "# adds together scores that represent active use, and normalises to 1 or 0\n",
    "def substance_sum(scores, newitem, item_name, num_scale_items):\n",
    "    printD(item_name)\n",
    "    if ((\"Nico\" in item_name) or (\"Mari\" in item_name) or (\"oke\" in item_name)):\n",
    "        printD(\"other substance \", item_name)\n",
    "        newitem = newitem.apply(lambda x: 0 if (x==2) else 1)\n",
    "    else:\n",
    "        printD(\"alcohol\", item_name)\n",
    "        newitem = newitem.add(-1,fill_value = 0)\n",
    "        \n",
    "    scores = scores.add(newitem,fill_value = 0)\n",
    "    scores = scores.apply(lambda x: 1 if(x>=1) else 0)\n",
    "    return scores\n",
    "\n",
    "# Checks if a text item has any text in it (1) or not (0)\n",
    "def hastext(scores, newitem, item_name, num_scale_items):\n",
    "    printD(item_name)\n",
    "    scores = scores.add(newitem.apply(lambda x: 0 if (x=='') else 1),fill_value=0)\n",
    "    scores = scores.apply(lambda x: 1 if (x>=1) else 0)\n",
    "    return scores\n",
    "\n",
    "# Changes a scale that has values (-1, 1) as options to (0,1)\n",
    "def na_to_0(scores, newitem, item_name, num_scale_items):\n",
    "    printD(item_name)\n",
    "    printD(\"new item value counts\")\n",
    "    printD(newitem.value_counts())\n",
    "    printD(\"scores item value counts\")\n",
    "    printD(scores.value_counts())\n",
    "    printD(newitem)\n",
    "    newitem = newitem.fillna(-1)\n",
    "    scores = scores.add(newitem.apply(lambda x: 0 if (x<0) else 1),fill_value=0)\n",
    "    scores = scores.apply(lambda x: 1 if (x>=1) else 0)\n",
    "    return scores\n",
    "\n",
    "def renumber_item(numbermap, default):\n",
    "    dmap = defaultdict(lambda: default, numbermap)\n",
    "    return lambda scores, newitem, item_name, num_scale_items: renumber(scores, newitem, item_name, num_scale_items, dmap)\n",
    "\n",
    "def renumber(scores, newitem, item_name, num_scale_items, numbermap):\n",
    "    printD(item_name)\n",
    "    printD(\"new item value counts\")\n",
    "    printD(newitem.value_counts())\n",
    "    printD(\"scores item value counts\")\n",
    "    printD(scores.value_counts())\n",
    "    printD(newitem)\n",
    "    scores = scores.add(newitem.apply(lambda x: numbermap[x]),fill_value=0)\n",
    "    return scores\n",
    "\n",
    "# adds one if they use media daily or more often\n",
    "# def media_sum(scores, newitem, item_name, num_scale_items):\n",
    "#     printD(item_name)\n",
    "    \n",
    "#     newitem = newitem.apply(lambda x: 1 if (x==2 or x==1) else 0)\n",
    "        \n",
    "#     scores = scores + newitem\n",
    "#     scores = scores.apply(lambda x: 1 if(x>=1) else 0)\n",
    "#     return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for scale (column-aggregate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psqi(scores, survey, scale_items):\n",
    "    com1_qual = survey.loc[:,\"PSQI_Q7\"].subtract(1, fill_value = 0)\n",
    "    \n",
    "    def psqi_fall(x):\n",
    "        import re\n",
    "        mins = 15\n",
    "        try:\n",
    "            mins = float(x)\n",
    "        except:\n",
    "            if (\"m\" in x):\n",
    "                try:\n",
    "                    mins = float(re.search('[0-9]', x).group())\n",
    "                except:\n",
    "                    pass\n",
    "            elif (\"h\" in x):\n",
    "                try:\n",
    "                    mins = 60 * float(re.search('[0-9]', x).group())\n",
    "                except:\n",
    "                    pass\n",
    "        if (mins > 120):\n",
    "            mins = 15\n",
    "        return mins\n",
    "    com2_1_fall = survey.loc[:,\"PSQI_Q2_FALL\"].apply(psqi_fall)\n",
    "    com2_1_fall = pd.cut(com2_1_fall, bins = [-10000,15,30,60,10000], labels = [0,1,2,3])\n",
    "    com2_2_cannot = survey.loc[:,\"PSQI_Q5_1\"]\n",
    "    com2_latency = pd.cut(com2_1_fall.add(com2_2_cannot, fill_value=0), bins = [-0.5,0.5,2.5,4.5,100], labels = [0,1,2,3])\n",
    "    \n",
    "    def psqi_hrs(x):\n",
    "        import re\n",
    "        hr = 7\n",
    "        try:\n",
    "            hr = float(re.search('[0-9]', x).group())\n",
    "        except:\n",
    "            hr = 7.0\n",
    "        return hr\n",
    "    com3_dur = pd.cut(survey.loc[:,\"PSQI_Q4_HOURS\"].apply(psqi_hrs), bins = [-1,5.1,6.1,7.1,24], labels = [3,2,1,0])\n",
    "    \n",
    "    def psqi_eff(x):\n",
    "        mins_sleep = 60.0 * x[\"PSQI_Q4_HOURS\"].apply(psqi_hrs)\n",
    "        fall = x[\"PSQI_Q2_FALL\"].apply(psqi_fall)\n",
    "        return 1 - fall / mins_sleep\n",
    "    com4_eff = pd.cut(psqi_eff(survey), bins = [0,0.65,0.75,0.85,1], labels = [3,2,1,0])\n",
    "    \n",
    "    def psqi_disturb(x):\n",
    "        cols = [\"PSQI_Q5_\" + str(i) for i in range(2,11)]\n",
    "        return x[cols].sum(axis = 1)\n",
    "    com5_eff = pd.cut(psqi_disturb(survey), bins = [-1, 0.5, 9.5, 18.5, 30], labels = [0,1,2,3])\n",
    "    com6_med = survey.loc[:,\"PSQI_Q6_1\"]\n",
    "    def psqi_dys(x):\n",
    "        return x[[\"PSQI_Q6_2\",\"PSQI_Q6_3\"]].sum(axis = 1)\n",
    "        return scores\n",
    "    com7_dys = pd.cut(psqi_dys(survey), bins = [-0.5,0.5, 2.5,4.5,100], labels = [0,1,2,3])\n",
    "    \n",
    "    return pd.concat([com1_qual,com2_latency,com3_dur,com4_eff,com5_eff,com6_med,com7_dys], axis = 1).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge Surveys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_surveys_by_row(config, dataconfig, mergeconfig, surveys):\n",
    "    survey_names = dataconfig[\"surveys\"]\n",
    "    \n",
    "    df_all = pd.DataFrame()\n",
    "    df_uw = pd.DataFrame()\n",
    "    df_cmu = pd.DataFrame()\n",
    "    \n",
    "    for survey_name in survey_names:\n",
    "        institute_name = \"\"\n",
    "        survey_type = \"\"\n",
    "        if (\"uw\" in survey_name):\n",
    "            survey_type = survey_name[3:]\n",
    "            institute_name = \"uw\"\n",
    "        else:\n",
    "            survey_type = survey_name[6:]\n",
    "            institute_name = \"cmu\"\n",
    "        surveys[survey_name][\"institute\"] = institute_name\n",
    "        surveys[survey_name][\"survey_type\"] = survey_type\n",
    "        \n",
    "        if (df_all.shape[0] == 0):\n",
    "            df_all = copy.deepcopy(surveys[survey_name])\n",
    "        else:\n",
    "            df_all = pd.concat([df_all, surveys[survey_name]])\n",
    "            \n",
    "        if (institute_name == \"uw\"):\n",
    "            if (df_uw.shape[0] == 0):\n",
    "                df_uw = copy.deepcopy(surveys[survey_name])\n",
    "            else:\n",
    "                df_uw = pd.concat([df_uw, surveys[survey_name]])\n",
    "        else:\n",
    "            if (df_cmu.shape[0] == 0):\n",
    "                df_cmu = copy.deepcopy(surveys[survey_name])\n",
    "            else:\n",
    "                df_cmu = pd.concat([df_cmu, surveys[survey_name]])\n",
    "        \n",
    "    return df_all, df_uw, df_cmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_surveys_by_column(config, dataconfig, mergeconfig, surveys):\n",
    "    survey_names = dataconfig[\"surveys\"]\n",
    "\n",
    "    # load the config info for how to merge\n",
    "    cols = mergeconfig[\"mergecols\"].keys()\n",
    "    left_index = bool(mergeconfig[\"left_index\"])\n",
    "    right_index = bool(mergeconfig[\"right_index\"])\n",
    "    how = mergeconfig[\"how\"]\n",
    "    nan = mergeconfig[\"nan\"]\n",
    "    merge_surveys = mergeconfig[\"surveys\"]\n",
    "    mergeindex = dataconfig[\"mergeindex\"]\n",
    "    print(\"surveys to merge together\")\n",
    "    print(merge_surveys)\n",
    "    # This will hold the final result\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    # loop through the surveys to merge\n",
    "    for suffix, survey_names in merge_surveys.items():\n",
    "        for survey_name in survey_names:\n",
    "            # Get the survey\n",
    "            right = copy.deepcopy(surveys[survey_name])\n",
    "            # To make it compatible with mergeconfig (which is used for merging by columns)\n",
    "            # rename the col names to append suffix\n",
    "            rename_cols = dict(zip([x for x in right.columns if x!=mergeindex],\n",
    "                         [x + \"_\" + dataconfig[survey_name][\"name\"] for x in right.columns if x!=mergeindex]))\n",
    "            right.rename(rename_cols, axis = 1, inplace = True)\n",
    "            \n",
    "            print(survey_name,\" \",right.shape,\"-------------------------------------------------\")\n",
    "            try:\n",
    "                print(\"printing out suicidality scores for \", survey_name)\n",
    "                if(\"cmuII_post\" in survey_name):\n",
    "                    print(right.BDI_II_Suicidality.value_counts())\n",
    "                elif (\"cmuII_baseline2\" in survey_name):\n",
    "                    print(right.BDI_II_Suicidality.value_counts())\n",
    "                elif (\"uw_baseline2\" in survey_name):\n",
    "                    print(right.BDI_II_Suicidality.value_counts())\n",
    "                elif (\"uw_post\" in survey_name):\n",
    "                    print(right.BDI_II_Suicidality.value_counts())\n",
    "                elif (\"uw_mid\" in survey_name):\n",
    "                    print(right.BDI_II_Suicidality.value_counts())\n",
    "            except:\n",
    "                print(\"\")\n",
    "            # narrow to columns of interest            \n",
    "#             print(\".\".join(cols))\n",
    "            useful_cols = right.columns.intersection(cols)\n",
    "            print(\".\".join(useful_cols))\n",
    "            right = right.loc[:, useful_cols]\n",
    "            print(useful_cols)\n",
    "            \n",
    "            # convert the index to specify a suffix\n",
    "            right.index = right.index.astype(str) + \"_\" + suffix\n",
    "\n",
    "            # Mergmerge_surveys_by_column into the global merge\n",
    "            if (df.shape[0] == 0):\n",
    "                df = copy.deepcopy(right)\n",
    "            else:\n",
    "                df = pd.merge(df, right, left_index=True, right_index=True, \n",
    "                          how=\"outer\", on = \"PID\")\n",
    "    return df\n",
    "\n",
    "def merge_scales(config, dataconfig, df):\n",
    "    print(df.shape)\n",
    "    # calculate the post merge scales, if any\n",
    "    # Load the json file that has the scale info in it\n",
    "    configdir = config[\"configdir\"]\n",
    "    with open(configdir+dataconfig[\"scaleconfig\"], 'r') as file_obj:\n",
    "        scaleconfig = json.load(file_obj)\n",
    "        file_obj.close()\n",
    "            \n",
    "    scales = scaleconfig[\"post_merged_scales\"]\n",
    "    print(scales)\n",
    "    \n",
    "    functions = scaleconfig[\"scale_functions\"]\n",
    "    for scale, function in functions.items():\n",
    "        functions[scale] = eval(function)\n",
    "    \n",
    "    df = calculate_scales(scales, functions, scaleconfig[\"scale_aggfunc_flag\"], df, 'ALL')\n",
    "\n",
    "#     display(HTML(df.head(n=10).to_html()))\n",
    "    \n",
    "    return df\n",
    "\n",
    "# tried to assign codes using category types but I couldn't get this working\n",
    "# XX TODO\n",
    "def merge_label_items(mergeconfig, df):\n",
    "    # create categorical variables and assign labels\n",
    "    for col in df.columns:\n",
    "        codes = []\n",
    "        try:\n",
    "            categories = mergeconfig[\"mergecols\"][col]\n",
    "            printD(\"found: \",col), col\n",
    "            codes = list(mergeconfig[\"mergecols\"][col].values())\n",
    "            categories = list(mergeconfig[\"mergecols\"][col].keys())\n",
    "        except:\n",
    "            print(\"No labels for: \", col)\n",
    "            codes = []\n",
    "        \n",
    "        if codes:\n",
    "            print(\"has labels...\", col)\n",
    "                \n",
    "            print(\"categories: \", categories)\n",
    "            print(codes)\n",
    "            \n",
    "            cat = pd.Categorical.from_codes(codes, categories=categories)\n",
    "                \n",
    "            print(cat)\n",
    "            df[col] = df[col].astype(cat)\n",
    "            print(\"res\", df[col])\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splits on the final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_datasets(dataconfig, df):\n",
    "    queries = dataconfig[\"datasets\"]\n",
    "    results = {}\n",
    "    results[\"all\"] = df\n",
    "    for name, query in queries.items():\n",
    "        results[name] = df.query(query)\n",
    "        print(\"name \", name)\n",
    "#         display(HTML(results[name].head(5).to_html()))\n",
    "   \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graveyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# textual columns whose na values should be ''\n",
    "all_text = ['ID','SES_7','SES_8','SES_9','SES_10','SES_11','SES_12','SES_13','SES_14','SES_15','SES_16',\n",
    "            'Contacts_2_TEXT','Contacts_3_TEXT',\n",
    "            'Contacts_4_TEXT','Contacts_5_TEXT',\n",
    "            'Contacts_6_TEXT','Contacts_7_TEXT',\n",
    "            'Contacts_8_TEXT',\n",
    "            'Contacts_9_TEXT','Contacts_10_TEXT',\n",
    "            'Contacts_11_TEXT',\n",
    "            'Contacts_12_TEXT','Contacts_13_TEXT',\n",
    "            'Contacts_14_TEXT',\n",
    "            'Contacts_15_TEXT','Contacts_16_TEXT',\n",
    "            'Contacts_17_TEXT',\n",
    "            'Contacts_18_TEXT','Contacts_19_TEXT',\n",
    "            'Contacts_20_TEXT',\n",
    "            'Contacts_21_TEXT',\n",
    "            'phoneProvider_TEXT',\n",
    "            'Orientation_Other','Orientation_TEXT',\n",
    "            'College_Other_TEXT','Major_DirectAdmit_TEXT',\n",
    "            'Major_Proposed_TEXT','Major_Second_TEXT',\n",
    "            'Major_1_TEXT','Major_2_TEXT','Major_3_TEXT',            \n",
    "            'Housing_Q1_TEXT','UsualLang',\n",
    "            'Race_TEXT',\n",
    "            'PSQI_Q1_BEDTIME','PSQI_Q2_FALL',\n",
    "            'PSQI_Q3_MORNTIME','PSQI_Q4_HOURS',\n",
    "            'PSQI_Q5_10_TEXT',\n",
    "            'SES_7','SES_8','SES_9',\n",
    "            'SES_10','SES_11','SES_12','SES_13','SES_14','SES_15','SES_16',\n",
    "            'UWEXP_Q9_TEXT','UWEXP_Services_Other_TEXT',\n",
    "            'MSLQ_Q1_TEXT','MLE_Q2_TEXT', 'MLE_Q5_2_TEXT',\n",
    "            'Sports_Q2_6_TEXT','Sports_Q4_6_TEXT', 'Sports_Q7_14_TEXT',\n",
    "            'SM_Usage_Q1_5_TEXT','SM_Usage_Q2_5_TEXT',\n",
    "            'CSU_Smoke_Q1C_TEXT','CSU_Smoke_Q1B_TEXT', 'CSU_Smoke_Q1D_TEXT','CSU_Smoke_Q1E_TEXT',\n",
    "            'CSU_Nico_Q2A_TEXT','CSU_Nico_Q2B_TEXT',\n",
    "            'CSU_Alch_Q3B_TEXT','CSU_Alch_Q4A_TEXT', 'CSU_Alch_Q5_TEXT','CSU_Alch_Q6_TEXT','CSU_Alch_Q7_TEXT',\n",
    "            'CSU_Mari_Q8A_TEXT',\n",
    "            'QID124_TEXT_fbb53c314b4b4eb3a88a8ed0Topics',\n",
    "            'FinalReflection']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
