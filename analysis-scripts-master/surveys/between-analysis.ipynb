{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statistics\n",
    "import visualizationutils as visutil\n",
    "import statsutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\\\n",
    "Specify the **absolute path** of the configuration file containing information about:\n",
    "\n",
    "- the independent data file and metrics\n",
    "- the dependent data file and metrics\n",
    "\n",
    "Note: Assumptions about input files:\n",
    "\n",
    "- independent metrics are categorical columns within independent data. This usually requires some sort \\\n",
    "of pre-processsing. For example, after cleaning baseline survey data and calculating the scores across \\\n",
    "various scales including depression scale (CES-D or BDI-II), we need to assign the category associated \\\n",
    "with each score ('YES', 'NO' for CES-D or 'NOT', 'LOW', 'MID', 'HIG') before using this file.\n",
    "- dependent metrics do not need any further filtering by any other information within dependent data. \\\n",
    "e.g. in processing main sleep, dependent data only includes main sleep information. \n",
    "- dependent metrics are always averaged for each PID. This means we compare the average values per participant.\n",
    "\n",
    "Example (find a sample config file in script-input repository): btw-sleep-baseline.json \n",
    "\n",
    "Tips:\n",
    "\n",
    "- Place your configuration files in the same directory as this notebook.\n",
    "- Use a different configuration file for each different analysis rather than modifying a single configuration file.\n",
    "  For example, have separate files for weekly surveys and EMA surveys.\n",
    "\n",
    "  \n",
    "\"\"\"\n",
    "#config_file = 'btw-sleep-baseline.json'\n",
    "config_file = input(prompt)\n",
    "print('using configurations specified in {}'.format(config_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_file, 'r') as file_obj:\n",
    "    config = json.load(file_obj)\n",
    "\n",
    "independent_data_file = config['independent_data']\n",
    "independent_metrics = config['independent_metrics']\n",
    "dependent_data_file = config['dependent_data']\n",
    "dependent_metrics = config['dependent_metrics']\n",
    "institutions = config['institutions']\n",
    "between_box = config['between_box']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "independent = pd.read_csv(independent_data_file)\n",
    "independent = independent[independent['institution'].isin(institutions)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify PID's in each group of a metric\n",
    "independent_grouping = {institution : \n",
    "                        {metric : independent[independent['institution'] == institution][['PID', metric]].groupby(by=metric)['PID'].unique() \n",
    "                         for metric in independent_metrics} \n",
    "                        for institution in institutions}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure PID's in each group of a metric do not overlap\n",
    "temp = independent_grouping.copy()\n",
    "for institution in institutions:\n",
    "    for metric in independent_metrics:\n",
    "        for group in independent_grouping[institution][metric].index:\n",
    "            other_pids = []\n",
    "            #print('evaluating pids of', group, 'in', metric, 'of', institution)\n",
    "            for other_group in independent_grouping[institution][metric].index:\n",
    "                if group == other_group:\n",
    "                    continue\n",
    "                #print('adding pids for', other_group, 'in', metric, 'of', institution)\n",
    "                other_pids.extend(independent_grouping[institution][metric][other_group])\n",
    "            pids = set(independent_grouping[institution][metric][group])\n",
    "            other_pids = set(other_pids)\n",
    "            temp[institution][metric][group] = list(pids - other_pids)\n",
    "            overlap = list(pids & other_pids)\n",
    "            if(len(overlap)) > 0 :\n",
    "                print('overlapping PIDs in {} of {}: {}'.format(metric, institution, overlap))\n",
    "independent_grouping = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependent = pd.read_csv(dependent_data_file)\n",
    "dependent = dependent[dependent['institution'].isin(institutions)] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate dependent data if necessary (e.g. avg sleep metrics for each PID)\n",
    "dependent = dependent.groupby(['PID', 'institution'])[dependent_metrics].mean()\n",
    "dependent = dependent.reset_index()\n",
    "# TO-DO make sure between comparison does not rely on PID being the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integrate a column in dependent data that associates rows of dependent data with categories of independent data\n",
    "for institution in institutions:\n",
    "    for metric in independent_metrics:\n",
    "        for group in independent_grouping[institution][metric].index:\n",
    "            dependent.loc[(dependent['PID'].isin(independent_grouping[institution][metric][group]))\n",
    "                          & (dependent['institution'] == institution), \n",
    "                          metric] = group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for institution in institutions:\n",
    "    print('data distribution in', institution)\n",
    "    visutil.distribution_graphs(independent_metrics, dependent_metrics, dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO Q-Q plots of normality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_normal = {metric : dependent.groupby(by=metric).apply(statsutils.is_normally_distributed, dependent_metrics) \n",
    "             for metric in independent_metrics}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## homogeneity of Variance (HOV) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test of HOV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: everything below this line is being refactored above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_normally_distributed(data, column, threshold=0.05):\n",
    "    # null hypothesis: data[column] comes from a normal distribution\n",
    "    k2, p = stats.normaltest(data[column])\n",
    "    if(p < threshold):\n",
    "        # we reject the null hypothesis, i.e. it is unlikely for the data to come from normal distribution\n",
    "        return False \n",
    "    # we maintain the null hypothesis, i.e. there is not enought evidence that data does not come from nomral distribution\n",
    "    return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_HOV_met(data1, data2, column, center='mean', threshold=0.05):\n",
    "    # null hypothesis: data1[column] and data2[column] have equal variances\n",
    "    w, p = stats.levene(data1[column], data2[column])\n",
    "    if(p < threshold):\n",
    "        # we reject the null hypothesis, i.e. the variances are unequal\n",
    "        return False \n",
    "    # we maintain the null hypothesis, i.e. there is not enought evidence that the variances are unequal\n",
    "    return True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-way ANOVA comparing affect ratings between participants who reported discrimination at least once and\n",
    "# those who did not report discrimination at all\n",
    "def between_comparison(independent_column_name, dependent_column_name, resps):\n",
    "    F, p =  stats.f_oneway(resps[resps[independent_column_name] == 'YES'][dependent_column_name], \n",
    "                           resps[resps[independent_column_name] == 'NO'][dependent_column_name])\n",
    "    #F, p = stats.mannwhitneyu(resps[resps['discriminated'] == 'YES'][dependent_column_name], \n",
    "    #                       resps[resps['discriminated'] == 'NO'][dependent_column_name]) # TO-DO test\n",
    "    print('one-way ANOVA on {} for {}: F = {:.2f}, p = {:.3f}'.format(dependent_column_name, \n",
    "                                                                      independent_column_name,\n",
    "                                                                      F, \n",
    "                                                                      p))\n",
    "    print('*****************')\n",
    "    return (F, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohen_d(x,y):\n",
    "# under the HOV assumption\n",
    "    nx = len(x)\n",
    "    ny = len(y)\n",
    "    dof = nx + ny - 2\n",
    "    mean_diff = np.mean(x) - np.mean(y)\n",
    "    pooled_var = ((nx-1)*(np.std(x, ddof=1) ** 2) + (ny-1)*(np.std(y, ddof=1) ** 2)) / dof\n",
    "    return mean_diff / np.sqrt(pooled_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_box_color(bp, color):\n",
    "    plt.setp(bp['boxes'], color=color)\n",
    "    plt.setp(bp['whiskers'], color=color)\n",
    "    plt.setp(bp['caps'], color=color)\n",
    "    plt.setp(bp['fliers'], color=color, marker = \".\")\n",
    "    plt.setp(bp['medians'], color=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_file = '/Users/yasaman/UWEXP/analysis-scripts/sensors/aggregation/results/sleep_aggregated.csv'\n",
    "step_file = '/Users/yasaman/UWEXP/analysis-scripts/sensors/aggregation/results/step_aggregated.csv'\n",
    "baseline_scores_file = '/Users/yasaman/UWEXP/analysis-scripts/surveys/results/baselines/baseline_scores_univ_pid_categorized.csv'\n",
    "sleep_between_box = '/Users/yasaman/UWEXP/analysis-scripts/surveys/results/baselines/sleep_between.png'\n",
    "step_between_box = '/Users/yasaman/UWEXP/analysis-scripts/surveys/results/baselines/step_between.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sleep_metrics = ['totalTimeInBed', 'totalMinutesAsleep', 'minutesAwake', 'minutesAsleep', 'efficiency']\n",
    "sleep_metrics = ['totalTimeInBed', 'totalMinutesAsleep']\n",
    "step_metrics = ['steps']\n",
    "scales = ['CES_D_POST', 'PSS_POST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep = pd.read_csv(sleep_file)\n",
    "step = pd.read_csv(step_file)\n",
    "baseline_scores = pd.read_csv(baseline_scores_file)\n",
    "baseline_scores_uw = baseline_scores[baseline_scores['institution'] == 'UW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pids_stressed = set(baseline_scores_uw[baseline_scores_uw['stressed'] == 'YES']['PID'].astype('int32').unique())\n",
    "pids_not_stressed = set(baseline_scores_uw[baseline_scores_uw['stressed'] == 'NO']['PID'].astype('int32').unique())\n",
    "pids_depressed = set(baseline_scores_uw[baseline_scores_uw['depressed'] == 'YES']['PID'].astype('int32').unique())\n",
    "pids_not_depressed = set(baseline_scores_uw[baseline_scores_uw['depressed'] == 'NO']['PID'].astype('int32').unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_pids = set(sleep['PID'].unique())\n",
    "between_sleep_avg = sleep[sleep['isMainSleep'] == True].groupby(['PID'])[sleep_metrics].mean()\n",
    "between_sleep_avg.loc[pids_stressed & sleep_pids, 'stressed'] = 'YES'\n",
    "between_sleep_avg.loc[pids_not_stressed & sleep_pids, 'stressed'] = 'NO'\n",
    "between_sleep_avg.loc[pids_depressed & sleep_pids, 'depressed'] = 'YES'\n",
    "between_sleep_avg.loc[pids_not_depressed & sleep_pids, 'depressed'] = 'NO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_avg_stressed_normality = [is_normally_distributed(between_sleep_avg[between_sleep_avg['stressed'] == 'YES'], \n",
    "                                                        metric, \n",
    "                                                        0.01) for metric in sleep_metrics]\n",
    "print('is sleep data normally distributed for people who have no reports of discrimination?', sleep_avg_stressed_normality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_avg_not_stressed_normality = [is_normally_distributed(between_sleep_avg[between_sleep_avg['stressed'] == 'NO'], \n",
    "                                                            metric, \n",
    "                                                            0.01) for metric in sleep_metrics]\n",
    "print('is sleep data normally distributed for people who have no reports of discrimination?', sleep_avg_not_stressed_normality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_HOV = [is_HOV_met(between_sleep_avg[between_sleep_avg['stressed'] == 'YES'],\n",
    "                        between_sleep_avg[between_sleep_avg['stressed'] == 'NO'],\n",
    "                        metric,\n",
    "                        'median', \n",
    "                        0.05) for metric in sleep_metrics]\n",
    "print('is sleep data for people who have reported discrimination and those who have not have equal variances?', sleep_HOV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[cohen_d(between_sleep_avg[between_sleep_avg['stressed'] == 'YES'][metric], \n",
    "         between_sleep_avg[between_sleep_avg['stressed'] == 'NO'][metric]) for metric in sleep_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[statistics.median(between_sleep_avg[between_sleep_avg['stressed'] == 'YES'][metric]) for metric in sleep_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[statistics.median(between_sleep_avg[between_sleep_avg['stressed'] == 'NO'][metric]) for metric in sleep_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_means_stressed = between_sleep_avg.groupby(['stressed'])[sleep_metrics].mean()\n",
    "print(group_means_stressed.T)\n",
    "mean_diff = group_means_stressed.loc['YES'] - group_means_stressed.loc['NO']\n",
    "print('the difference in sleep metrics in people who are stressed')\n",
    "print('NOTE: positive difference means metrics are larger in people who are stressed')\n",
    "print('all time measures are in minutes')\n",
    "print(mean_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_means_depressed = between_sleep_avg.groupby(['depressed'])[sleep_metrics].mean()\n",
    "print(group_means_depressed.T)\n",
    "mean_diff = group_means_depressed.loc['YES'] - group_means_depressed.loc['NO']\n",
    "print('the difference in sleep metrics in people who are depressed')\n",
    "print('NOTE: positive difference means metrics are larger in people who are depressed')\n",
    "print('all time measures are in minutes')\n",
    "print(mean_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stressed_between = [between_comparison('stressed', \n",
    "                                       metric, \n",
    "                                       between_sleep_avg[~between_sleep_avg['stressed'].isna()]) for metric in sleep_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depressed_between = [between_comparison('depressed', \n",
    "                                        metric, \n",
    "                                        between_sleep_avg[~between_sleep_avg['depressed'].isna()]) for metric in sleep_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stressed_yes = [between_sleep_avg[between_sleep_avg['stressed'] == 'YES'][metric] for metric in sleep_metrics]\n",
    "stressed_no = [between_sleep_avg[between_sleep_avg['stressed'] == 'NO'][metric] for metric in sleep_metrics]\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "bpl = plt.boxplot(stressed_yes, \n",
    "                  positions=np.array(range(len(sleep_metrics)))*2.0-0.4, \n",
    "                  sym='', widths=0.6)\n",
    "bpr = plt.boxplot(stressed_no, \n",
    "                  positions=np.array(range(len(sleep_metrics)))*2.0+0.4, \n",
    "                  sym='', widths=0.6)\n",
    "set_box_color(bpl, '#D7191C') # colors are from http://colorbrewer2.org/\n",
    "set_box_color(bpr, '#2C7BB6')\n",
    "\n",
    "# draw temporary red and blue lines and use them to create a legend\n",
    "plt.plot([], c='#D7191C', label='stressed (PSS >= 20)')\n",
    "plt.plot([], c='#2C7BB6', label='not stressed (PSS < 20)')\n",
    "plt.legend(ncol = 2)\n",
    "plt.ylabel('Sleep Metrics (in min)')\n",
    "plt.xticks(range(0, len(sleep_metrics) * 2, 2), sleep_metrics)\n",
    "plt.xlim(-1, len(sleep_metrics)*2-1)\n",
    "plt.ylim(300, 600)\n",
    "plt.tight_layout()\n",
    "plt.savefig(sleep_between_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_pids = set(step['PID'].unique())\n",
    "between_step_avg = step.groupby(['PID'])[step_metrics].mean()\n",
    "between_step_avg.loc[pids_stressed & step_pids, 'stressed'] = 'YES'\n",
    "between_step_avg.loc[pids_not_stressed & step_pids, 'stressed'] = 'NO'\n",
    "between_step_avg.loc[pids_depressed & step_pids, 'depressed'] = 'YES'\n",
    "between_step_avg.loc[pids_not_depressed & step_pids, 'depressed'] = 'NO'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_avg_stressed_normality = is_normally_distributed(between_step_avg[between_step_avg['stressed'] == 'YES'], \n",
    "                                                      'steps', \n",
    "                                                      0.01)\n",
    "print('is steps data normally distributed for people who reported discrimination?', step_avg_stressed_normality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO-DO plot step data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_avg_not_stressed_normality = is_normally_distributed(between_step_avg[between_step_avg['stressed'] == 'NO'], \n",
    "                                                          'steps', \n",
    "                                                          0.01)\n",
    "print('is steps data normally distributed for people who have no reports of discrimination?', step_avg_not_stressed_normality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_HOV = is_HOV_met(between_step_avg[between_step_avg['stressed'] == 'YES'],\n",
    "                      between_step_avg[between_step_avg['stressed'] == 'NO'],\n",
    "                      'steps',\n",
    "                      'median', \n",
    "                      0.05)\n",
    "print('is steps data for people who have reported discrimination and those who have not have equal variances?', step_HOV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohen_d(between_step_avg[between_step_avg['stressed'] == 'YES']['steps'], \n",
    "        between_step_avg[between_step_avg['stressed'] == 'NO']['steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_means_stressed = between_step_avg.groupby(['stressed'])[step_metrics].mean()\n",
    "print(group_means_stressed.T)\n",
    "mean_diff = group_means_stressed.loc['YES'] - group_means_stressed.loc['NO']\n",
    "print('the difference in step metrics in people who are stressed')\n",
    "print('NOTE: positive difference means metrics are larger in people who are stressed')\n",
    "print(mean_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(between_step_avg[between_step_avg['stressed'] == 'YES'], ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.median(between_step_avg[between_step_avg['stressed'] == 'YES']['steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics.median(between_step_avg[between_step_avg['stressed'] == 'NO']['steps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_means_depressed = between_step_avg.groupby(['depressed'])[step_metrics].mean()\n",
    "print(group_means_depressed.T)\n",
    "mean_diff = group_means_depressed.loc['YES'] - group_means_depressed.loc['NO']\n",
    "print('the difference in step metrics in people who are depressed')\n",
    "print('NOTE: positive difference means metrics are larger in people who are depressed')\n",
    "print(mean_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stressed_between = [between_comparison('stressed', \n",
    "                                       metric, \n",
    "                                       between_step_avg[~between_step_avg['stressed'].isna()]) for metric in step_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "depressed_between = [between_comparison('depressed', \n",
    "                                        metric, \n",
    "                                        between_step_avg[~between_step_avg['depressed'].isna()]) for metric in step_metrics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stressed_yes = [between_step_avg[between_step_avg['stressed'] == 'YES'][metric] for metric in step_metrics]\n",
    "stressed_no = [between_step_avg[between_step_avg['stressed'] == 'NO'][metric] for metric in step_metrics]\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "bpl = plt.boxplot(stressed_yes, \n",
    "                  positions=np.array(range(len(step_metrics)))*2.0-0.4, \n",
    "                  sym='', widths=0.6)\n",
    "bpr = plt.boxplot(stressed_no, \n",
    "                  positions=np.array(range(len(step_metrics)))*2.0+0.4, \n",
    "                  sym='', widths=0.6)\n",
    "set_box_color(bpl, '#D7191C') # colors are from http://colorbrewer2.org/\n",
    "set_box_color(bpr, '#2C7BB6')\n",
    "\n",
    "# draw temporary red and blue lines and use them to create a legend\n",
    "plt.plot([], c='#D7191C', label='stressed (PSS >= 20)')\n",
    "plt.plot([], c='#2C7BB6', label='not stressed (PSS < 20)')\n",
    "plt.legend(ncol = 2)\n",
    "plt.ylabel('Daily Number of Steps')\n",
    "plt.xticks(range(0, len(step_metrics) * 2, 2), step_metrics)\n",
    "plt.xlim(-1, len(step_metrics)*2-1)\n",
    "plt.ylim(1500, 18000)\n",
    "plt.tight_layout()\n",
    "step_between_box = '/Users/yasaman/UWEXP/analysis-scripts/surveys/results/baselines/step_between.png'\n",
    "plt.savefig(step_between_box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
