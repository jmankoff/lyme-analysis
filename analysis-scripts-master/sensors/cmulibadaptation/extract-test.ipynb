{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "from pytz import UTC\n",
    "from pytz import timezone\n",
    "import json\n",
    "from library.utils.setting import DATA_SPLITS_STUDY_START_DATE, DATA_SPLITS_STUDY_END_DATE\n",
    "from utils.getDataSplits import getDaywiseSplitsForEpoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '/Users/yasaman/UWEXP/data/aggregated/calls_test.txt'\n",
    "data_types = {\n",
    "       \"_id\": \"int32\", \n",
    "      \"timestamp\": \"int64\", \n",
    "      \"device_id\": \"str\", \n",
    "      \"call_type\": \"int32\", \n",
    "      \"call_duration\": \"int32\", \n",
    "      \"trace\": \"str\"\n",
    "}\n",
    "data = pd.read_csv(data_file,\n",
    "                   header=0,\n",
    "                   dtype=data_types,\n",
    "                   sep='\\t', \n",
    "                   lineterminator='\\n',\n",
    "                   encoding = \"ISO-8859-1\")\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_types_file = '/Users/yasaman/UWEXP/script-input/sensors/device_id_type.json'\n",
    "with open(device_types_file, 'r') as fileObj:\n",
    "    device_types = json.load(fileObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iOS\n",
    "INCOMING_IOS = 1\n",
    "CONNECTED_IOS = 2\n",
    "DIALING_IOS = 3\n",
    "DISCONNECTED_IOS = 4\n",
    "# Android (reference)\n",
    "INCOMING = 1\n",
    "OUTGOING = 2\n",
    "MISSED = 3\n",
    "def combine_ios_records(session:pd.DataFrame, columns:list, device_types:dict)->pd.DataFrame:\n",
    "    \"\"\"\\\n",
    "    Combines information of iOS records belonging to a certain call session of a certain device_id \n",
    "    to produce a single record to represent the call session as incoming, outgoing, or missed in a\n",
    "    way that resembles how information are recorded for Android calls.\n",
    "    \"\"\"\n",
    "    device_id = session['device_id'].iloc[0]\n",
    "    if device_id not in device_types:\n",
    "        print('device type not available for {}'.format(device_id))\n",
    "        return pd.DataFrame(columns=columns)\n",
    "    device_type = device_types[device_id]\n",
    "    trace = session['trace'].iloc[0]\n",
    "    \n",
    "    if device_type == 'iOS':\n",
    "        session_states = session['call_type'].unique()\n",
    "        \n",
    "        if DISCONNECTED_IOS not in session_states:\n",
    "            print('iOS call sessions must have a disconnected state\\n\\t not the case in {}'.format(trace))\n",
    "            return pd.DataFrame(columns=columns)\n",
    "        \n",
    "        if INCOMING_IOS in session_states and DIALING_IOS in session_states:\n",
    "            print('iOS call sessions cannot be both incoming and outgoing\\n\\t not the case in {}'.format(trace))\n",
    "            return pd.DataFrame(columns=columns)\n",
    "        \n",
    "        if CONNECTED_IOS not in session_states:\n",
    "            call_type = MISSED\n",
    "            if DIALING_IOS in session_states:\n",
    "                # NOTE depending on how Android record unsuccessful outgoing calls I may need to\n",
    "                #      discard records with DIALING_IOS in their sessions\n",
    "                #print('iOS call sessions of dialing a number but not connecting are discarded')\n",
    "                #return pd.DataFrame(columns=columns)\n",
    "                pass\n",
    "        else:\n",
    "            session = session[session['call_type'] != CONNECTED_IOS]\n",
    "            if INCOMING_IOS in session_states:\n",
    "                call_type = INCOMING\n",
    "            if DIALING_IOS in session_states:\n",
    "                call_type = OUTGOING\n",
    "        \n",
    "        if len(session[session['call_type'] == INCOMING_IOS]) > 1:\n",
    "            print('multiple incoming records found for iOS call session {}'.format(trace))\n",
    "        \n",
    "        if len(session[session['call_type'] == DIALING_IOS]) > 1:\n",
    "            print('multiple dialing records found for iOS call session {}'.format(trace))\n",
    "        \n",
    "        if len(session[session['call_type'] == DISCONNECTED_IOS]) > 1:\n",
    "            print('multiple disconnected records found for iOS call session {}'.format(trace))\n",
    "        \n",
    "        call_duration = session.sort_values(by=['call_type', 'call_duration'], \n",
    "                                            ascending=[False, False])['call_duration'].iloc[0]\n",
    "        \n",
    "        session_summary = session.sort_values(by='call_type').iloc[0]\n",
    "        session_summary['call_type'] = call_type\n",
    "        session_summary['call_duration'] = call_duration\n",
    "        session_summary = pd.DataFrame([session_summary[columns]])\n",
    "        return session_summary\n",
    "    else:\n",
    "        return session[columns]\n",
    "\n",
    "#def correct_ios_coding(table:pd.DataFrame, device_types_file:str)->pd.DataFrame:\n",
    "#    if table.shape[0] == 0:\n",
    "#        return table\n",
    "#    with open(device_types_file, 'r') as fileObj:\n",
    "#        device_types = json.load(fileObj)\n",
    "#    table = table.groupby(by=['device_id', 'trace']).apply(combine_ios_records, device_types)\n",
    "#    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "org_columns = list(data.columns)\n",
    "columns = org_columns.copy()\n",
    "columns.remove('device_id')\n",
    "columns.remove('trace')\n",
    "#data.groupby(by=['device_id', 'trace']).apply(combine_ios_records, columns, device_types).reset_index()[org_columns].sort_values('_id')\n",
    "data.groupby(by=['device_id', 'trace'], as_index=False).apply(combine_ios_records, org_columns, device_types).sort_values('_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_timezone(df:pd.DataFrame, tz_:str='US/Eastern', cols:dict={'timestamp':'datetime_EST'}) -> None:\n",
    "    \"\"\"\\\n",
    "    converts columns of dataframe df to timezone and adds them to the dataframe under the associated name\n",
    "    NOTE that the changes happen in place\n",
    "    \"\"\"\n",
    "    \n",
    "    # TO-DO check if tz_ is a valid timezone specifier\n",
    "\n",
    "    datetimes = df[list(cols.keys())].apply(pd.to_datetime, unit = 'ms', errors='coerce') # with errors='coerce', invalid parsing will be set as NaT\n",
    "    tz_ = timezone(tz_)\n",
    "    for col in cols:\n",
    "        df[cols[col]] = datetimes[col].apply(lambda t: t.tz_localize(UTC, \n",
    "                                                                     ambiguous='NaT', \n",
    "                                                                     errors='coerce').astimezone(tz_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_timezone(data, 'US/Pacific', {'timestamp':'timestamp_PST'})\n",
    "data.set_index(\"timestamp_PST\", inplace=True)\n",
    "data = data.tz_localize(None)\n",
    "print(data.shape)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tz_localize(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_ = np.array((1516521600, 1516780800))\n",
    "to_ = np.array((1516780799, 1517039999))\n",
    "timeranges = np.column_stack((from_,to_))\n",
    "timeranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeranges = getDaywiseSplitsForEpoch(\"night\")\n",
    "timeranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_arguments_file = '/Users/yasaman/UWEXP/script-input/sensors/location-feature-additionalargs.json'\n",
    "with open(additional_arguments_file, 'r') as fileObj:\n",
    "    arguments = json.load(fileObj)\n",
    "periods = arguments['on_site_periods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "periodranges = np.ndarray(shape=(len(periods), 2), dtype=np.int64)\n",
    "for index, period in enumerate(periods):\n",
    "    start = period['start']\n",
    "    start = datetime.datetime(start['year'], \n",
    "                              start['month'], \n",
    "                              start['day'], \n",
    "                              start['hour'], \n",
    "                              start['minute'], \n",
    "                              start['second'])\n",
    "    start = time.mktime(start.timetuple())\n",
    "    end = period['end']\n",
    "    end = datetime.datetime(end['year'],\n",
    "                            end['month'], \n",
    "                            end['day'], \n",
    "                            end['hour'], \n",
    "                            end['minute'], \n",
    "                            end['second'])\n",
    "    end = time.mktime(end.timetuple())\n",
    "    periodranges[index, 0] = start\n",
    "    periodranges[index, 1] = end\n",
    "periodranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YSS\n",
    "def in_range(range_:pd.Series, df:pd.DataFrame)->pd.Series:\n",
    "    \"\"\"\\\n",
    "    Returns the boolean indices of rows in dataframe df that fall within range_ (inclusive)\n",
    "    \"\"\"\n",
    "    ind  = (df['timestamp'] >= range_['from']) & (df['timestamp'] <= range_['to'])\n",
    "    return ind\n",
    "\n",
    "# YSS\n",
    "def timerange_filter(df:pd.DataFrame, timeranges:np.ndarray)->pd.DataFrame:\n",
    "    \"\"\"\\\n",
    "    Returns the filter that can be used to get all the rows of dataframe df where \n",
    "    timestamp column falls in timeranges, a 2D NumPy array with start time in the\n",
    "    first column and end time in the second column.\n",
    "    \"\"\"\n",
    "\n",
    "    timeranges = pd.DataFrame(timeranges, columns=['from', 'to'])\n",
    "    inds = timeranges.apply(lambda x : in_range(x, df), axis = 1)\n",
    "    return inds.T.any(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_filter = timerange_filter(data, timeranges * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "period_filter = timerange_filter(data, periodranges * 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def badd_data(df:pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\\\n",
    "    Returns the total and average frqeuncy each bluetooth address appears \n",
    "    as well as the number of days that address appears. Total and average\n",
    "    are obtained from the daily frequency values.\n",
    "    \"\"\"\n",
    "\n",
    "    # find the daily frequnecy of each bluetooth address\n",
    "    freq_table = df.groupby(by=[pd.to_datetime(df['timestamp'], unit='ms').dt.date, 'bt_address'], \n",
    "                            as_index=False).size().reset_index()\n",
    "    freq_table.rename({'timestamp':'date', 0:'freq'}, axis=\"columns\", inplace=True)\n",
    "    \n",
    "    # find the total and average frequency as well as the number of days \n",
    "    # of each bluetooth address and store them in baddress_freq_data\n",
    "    baddress_freq_data = freq_table.groupby(by='bt_address').agg([np.mean, np.size, np.sum]).reset_index()\n",
    "    baddress_freq_data.columns = ['bt_address', 'avgfreq', 'numdays', 'freq']\n",
    "    baddress_freq_data.sort_values(by=['freq'], ascending=False, inplace=True)\n",
    "    return baddress_freq_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badd_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANDROID_WALKING_NAME = 'walking'\n",
    "ANDROID_RUNNING_NAME = 'running'\n",
    "ANDROID_ON_FOOT_NAME = 'on_foot'\n",
    "ANDROID_IN_VEHICLE_NAME = 'on_bicycle'\n",
    "ANDROID_ON_BICYCLE_NAME = 'in_vehicle'\n",
    "ANDROID_STILL_NAME = 'still'\n",
    "ANDROID_TILTING_NAME = 'tilting'\n",
    "ANDROID_UNKNOWN_NAME = 'unknown'\n",
    "ANDROID_WALKING_TYPE = 7\n",
    "ANDROID_RUNNING_TYPE = 8\n",
    "ANDROID_ON_FOOT_TYPE = 2\n",
    "ANDROID_IN_VEHICLE_TYPE = 0\n",
    "ANDROID_ON_BICYCLE_TYPE = 1\n",
    "ANDROID_STILL_TYPE = 3\n",
    "ANDROID_TILTING_TYPE = 5\n",
    "ANDROID_UNKNOWN_TYPE = 4\n",
    "\n",
    "def androidize_iOSactivity(row):\n",
    "    \"\"\"\\\n",
    "    Returns the activiy_type and activity_name information for a given row in \n",
    "    iOS activity table so iOS tables can be processed using the same library \n",
    "    functions developed for Android activity. Note that if there are more than\n",
    "    a single activity labeled (e.g. in UW phase I we have records with both \n",
    "    stationary = 1 and automotiva = 1), the one higher up here is considered. \n",
    "    That is: walking > running > cycling > automotive > stationary > unknown\n",
    "    \"\"\"\n",
    "    if row['walking'] == 1:\n",
    "        return (ANDROID_WALKING_TYPE, ANDROID_WALKING_NAME)\n",
    "    if row['running'] == 1:\n",
    "        return (ANDROID_RUNNING_TYPE, ANDROID_RUNNING_NAME)\n",
    "    if row['cycling'] == 1:\n",
    "        return (ANDROID_ON_BICYCLE_TYPE, ANDROID_ON_BICYCLE_NAME)\n",
    "    if row['automotive'] == 1:\n",
    "        return (ANDROID_IN_VEHICLE_TYPE, ANDROID_IN_VEHICLE_NAME)\n",
    "    if row['stationary'] == 1:\n",
    "        return (ANDROID_STILL_TYPE, ANDROID_STILL_NAME)\n",
    "    if row['unknown'] == 1:\n",
    "        return (ANDROID_UNKNOWN_TYPE, ANDROID_UNKNOWN_NAME)\n",
    "    return (None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['activities'].notnull()]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[['activity_type', 'activity_name']] = data.apply(lambda x: androidize_iOSactivity(x), \n",
    "#                                                      axis=1).apply(pd.Series)\n",
    "androidized_columns = data.apply(lambda x: androidize_iOSactivity(x), axis=1).apply(pd.Series)\n",
    "data.loc[:, 'activity_type'] = androidized_columns[0]\n",
    "data.loc[:, 'activity_name'] = androidized_columns[1]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['activity_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['activity_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highest_confidence_and_priority(df, priority_list, columns):\n",
    "    \"\"\"\\\n",
    "    Returns the desired columns of the row of df with the highest confidence\n",
    "    and priority. The larger the confidence value, the more confident and the\n",
    "    larger the index on the priority list, the higher the priority\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['activity_name'] = pd.Categorical(df['activity_name'], priority_list)\n",
    "    df = df.sort_values(by=['confidence', 'activity_name'], ascending=[False, False])\n",
    "    return df[columns].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = data.copy()\n",
    "activity_priority_list = [ANDROID_WALKING_NAME, \n",
    "                          ANDROID_RUNNING_NAME, \n",
    "                          ANDROID_ON_FOOT_NAME, \n",
    "                          ANDROID_IN_VEHICLE_NAME, \n",
    "                          ANDROID_ON_BICYCLE_NAME, \n",
    "                          ANDROID_STILL_NAME, \n",
    "                          ANDROID_TILTING_NAME, \n",
    "                          ANDROID_UNKNOWN_NAME]\n",
    "columns_to_keep = list(data.columns)\n",
    "columns_to_keep.remove('timestamp')\n",
    "data = data.groupby('timestamp').apply(highest_confidence_and_priority, \n",
    "                                       activity_priority_list[::-1],\n",
    "                                       columns_to_keep).reset_index()[data.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "                    'activity_type' : ['still', \n",
    "                                       'running', \n",
    "                                       'walking',\n",
    "                                       'in_vehicle',\n",
    "                                       'still', \n",
    "                                       'tilting',\n",
    "                                       'walking',\n",
    "                                       'in_vehicle',\n",
    "                                       'unknown',\n",
    "                                       'running',\n",
    "                                       'on_bicycle',\n",
    "                                       'on_foot',\n",
    "                                       'unknown',\n",
    "                                       'on_bicycle',\n",
    "                                       'tilting',\n",
    "                                       'on_foot'\n",
    "                                       ],\n",
    "                    'confidence' : [2,\n",
    "                                    1,\n",
    "                                    2,\n",
    "                                    1,\n",
    "                                    1,\n",
    "                                    1,\n",
    "                                    1,\n",
    "                                    2,\n",
    "                                    2,\n",
    "                                    2,\n",
    "                                    1,\n",
    "                                    2,\n",
    "                                    1,\n",
    "                                    2,\n",
    "                                    2,\n",
    "                                    1],\n",
    "                    'timestamp': [0,\n",
    "                                  0, \n",
    "                                  0, \n",
    "                                  0, \n",
    "                                  0, \n",
    "                                  0,\n",
    "                                  0,\n",
    "                                  0,\n",
    "                                  0,\n",
    "                                  0, \n",
    "                                  0, \n",
    "                                  0, \n",
    "                                  0, \n",
    "                                  0,\n",
    "                                  0,\n",
    "                                  0],\n",
    "                  })\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activity_priority_list = [ANDROID_WALKING_NAME, \n",
    "                          ANDROID_RUNNING_NAME, \n",
    "                          ANDROID_ON_FOOT_NAME, \n",
    "                          ANDROID_IN_VEHICLE_NAME, \n",
    "                          ANDROID_ON_BICYCLE_NAME, \n",
    "                          ANDROID_STILL_NAME, \n",
    "                          ANDROID_TILTING_NAME, \n",
    "                          ANDROID_UNKNOWN_NAME]\n",
    "df['activity_name'] = pd.Categorical(df['activity_type'], activity_priority_list[::-1])\n",
    "df.sort_values(by=['confidence', 'activity_name'], ascending=[False, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df.copy()\n",
    "columns_to_keep = list(df.columns)\n",
    "columns_to_keep.remove('timestamp')\n",
    "df = df.groupby('timestamp').apply(highest_confidence_and_priority, \n",
    "                                   activity_priority_list[::-1],\n",
    "                                   columns_to_keep).reset_index()[df.columns]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_reliable(df, columns):\n",
    "    \"\"\"\\\n",
    "    Returns the desired columns of the most important row of df. The importance\n",
    "    is defined as (1) being inferred as conversation (-1) > voice (1) > noise (2), \n",
    "    (2) having the highest energy / amplitude, (3) having the latest start time (only \n",
    "    applicable to conversations), (4) having the earliest end time (only applicable \n",
    "    to conversations).\n",
    "    \"\"\"\n",
    "    df = df.sort_values(by=['inference', \n",
    "                            'double_energy',\n",
    "                            'double_convo_start',\n",
    "                            'double_convo_end'], \n",
    "                        ascending=[True, \n",
    "                                   False,\n",
    "                                   False,\n",
    "                                   True])\n",
    "    return df[columns].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = data.copy()\n",
    "columns_to_keep = list(data.columns)\n",
    "columns_to_keep.remove('timestamp')\n",
    "data = data.groupby('timestamp').apply(most_reliable, \n",
    "                                       columns_to_keep).reset_index()[data.columns]\n",
    "data.rename(index=str, columns={'double_energy' : 'energy', \n",
    "                                'double_convo_start' : 'convo_start', \n",
    "                                'double_convo_end' : 'convo_end'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = data_.groupby('timestamp').size()\n",
    "multi = records[records > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_[data_['timestamp'].isin(list(multi.keys()))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['timestamp'].isin(list(multi.keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape[0], '---', data[data['activity_name'].notnull()].shape[0])\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data['timestamp'].isin(list(multi.keys()))]['inference'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_test(df):\n",
    "    print(\"you'll see a new column with name new_col added to df.\")\n",
    "    print(\"if your df already has a new_col column its value is going to become 9\")\n",
    "    df['new_col'] = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "                    'col1' : ['A', 'A', 'B', np.nan, 'D', 'C'],\n",
    "                    'col2' : [2, 1, 9, 8, 7, 4],\n",
    "                    'col3': [0, 1, 9, 4, 2, 3],\n",
    "                  })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.info())\n",
    "function_test(df)\n",
    "print(df.info())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
