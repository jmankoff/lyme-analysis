{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_normal_sensors_folder = r\"C:\\Users\\orson\\Desktop\\Myself\\HCI\\UWiSchool\\Projects\\UWEXP\\Data\\UWEXPI\\UW_I_features\"\n",
    "path_to_sleep_merged_file = r\"C:\\Users\\orson\\Desktop\\Myself\\HCI\\UWiSchool\\Projects\\UWEXP\\Data\\UWEXPI_SampleData\\glue\\aggregated_horizontal_sleep.csv\"\n",
    "path_to_ema_merged_file = r\"C:\\Users\\orson\\Desktop\\Myself\\HCI\\UWiSchool\\Projects\\UWEXP\\Data\\UWEXPI_SampleData\\glue\\aggregated-horizontal-numVal-internalID.csv\"\n",
    "path_to_baseline_merged_file = r\"C:\\Users\\orson\\Desktop\\Myself\\HCI\\UWiSchool\\Projects\\UWEXP\\Data\\UWEXPI_SampleData\\glue\\merged_by_row_uw.csv\"\n",
    "path_to_save_giant_table = r\"C:\\Users\\orson\\Desktop\\Myself\\HCI\\UWiSchool\\Projects\\UWEXP\\Data\\UWEXPI_SampleData\\glue\"\n",
    "pid_list_file = r\"C:\\Users\\orson\\Desktop\\Myself\\HCI\\UWiSchool\\Projects\\UWEXP\\Data\\UWEXPI_SampleData\\glue\\pids.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the table for sensors (excluding fitbit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(pid_list_file, \"r\") as f:\n",
    "    pid_list = f.readlines()\n",
    "pid_list = [x.strip() for x in pid_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_list = []\n",
    "for i in os.listdir(path_to_normal_sensors_folder):\n",
    "    pid_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid_list = [\"002\", \"014\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_sensors = [\"activity_android\", \"activity_ios\", \"applications\", \"audio\", \"battery\", \"bluetooth\",\n",
    "    \"calls\", \"locations\", \"screen\", \"wifi\"]\n",
    "epochs = [\"allday\", \"morning\", \"afternoon\", \"evening\", \"night\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deprecated\n",
    "def get_sleep_table(path_to_sleep_folder, pid):\n",
    "    df_sleep = pd.read_csv(\"{}/PID{}_sleep.csv\".format(path_to_sleep_folder,\n",
    "                                                 pid),\n",
    "                           sep=',',\n",
    "                           encoding = \"ISO-8859-1\")\n",
    "    df_sleep[\"participantID\"] = pid\n",
    "    df_sleep.rename({\"participantID\":\"pid\", \"date\":\"time\"}, inplace = True, axis = 1)\n",
    "    sleep_feature_column = [x for x in df_sleep.columns if x not in [\"pid\",\"time\"]]\n",
    "    df_sleep_main = copy.deepcopy(df_sleep[df_sleep[\"isMainSleep\"] == True])\n",
    "    df_sleep_main.drop([\"isMainSleep\"], inplace = True, axis = 1)\n",
    "    df_sleep_notmain = copy.deepcopy(df_sleep[df_sleep[\"isMainSleep\"] != True])\n",
    "    df_sleep_notmain.drop([\"isMainSleep\"], inplace = True, axis = 1)\n",
    "    df_sleep_main.rename(dict(zip(sleep_feature_column, [x + \"_main\" for x in sleep_feature_column])), inplace = True, axis = 1)\n",
    "    df_sleep_notmain.rename(dict(zip(sleep_feature_column, [x + \"_notmain\" for x in sleep_feature_column])), inplace = True, axis = 1)\n",
    "    df_sleep_merge = df_sleep_main.merge(df_sleep_notmain, on = [\"pid\", \"time\"], how = \"outer\")\n",
    "    return df_sleep_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pid = pid_list[0]\n",
    "giant_table_sensor = pd.DataFrame()\n",
    "giant_table_sensor_pids = []\n",
    "\n",
    "admin_cols = [\"PID\", \"date\",  \"epoch\", \"weekday\", \"grouping\", \"epoch_weekday_grouping_abbreviated\"]\n",
    "\n",
    "for pid in pid_list:\n",
    "    sensors_tables = {}\n",
    "    for sensor in normal_sensors:\n",
    "        sensors_tables[sensor] = {}\n",
    "        df_buf = pd.read_csv(\"{}/{}/{}.txt\".format(path_to_normal_sensors_folder,\n",
    "                                                                     pid,sensor),\n",
    "                                                                     sep='\\t',\n",
    "                                                                     encoding = \"ISO-8859-1\")\n",
    "        df_buf[\"pid\"] = pid\n",
    "        df_buf.rename({\"time\":\"date\", \"pid\":\"PID\"}, axis = 1, inplace = True)\n",
    "        df_buf[\"date\"] = pd.to_datetime(df_buf[\"date\"])\n",
    "        # currenlty we only look at daily data\n",
    "        df_buf = df_buf[(df_buf[\"grouping\"] == \"day\") & (df_buf[\"weekday\"] == \"wk\")]\n",
    "        df_buf.drop(columns = [\"weekday\",\n",
    "                                \"grouping\",\n",
    "                                \"epoch_weekday_grouping_abbreviated\"],\n",
    "                    inplace = True)\n",
    "#         sensors_tables[sensor][\"df\"] = deepcopy(df_buf)\n",
    "        sensors_tables[sensor][\"feature_cols\"] = [x for x in df_buf.columns if x not in admin_cols]\n",
    "        sensors_tables[sensor][\"epochs\"] = {}\n",
    "#         sensors_tables[sensor][\"epoch_merged\"] = pd.DataFrame()\n",
    "        for epoch in epochs:\n",
    "            sensors_tables[sensor][\"epochs\"][epoch] = deepcopy(df_buf[df_buf[\"epoch\"] == epoch]).drop(columns = [\"epoch\"])\n",
    "            sensors_tables[sensor][\"epochs\"][epoch].rename(dict(zip(\n",
    "                sensors_tables[sensor][\"feature_cols\"],\n",
    "                [x + \"_\" + epoch for x in sensors_tables[sensor][\"feature_cols\"]])), axis = 1, inplace = True)\n",
    "    giant_table_sensor_pid = pd.DataFrame()\n",
    "    android_ios_flag = sensors_tables[\"activity_ios\"][\"epochs\"][epochs[0]].shape[0] == 0\n",
    "    for sensor in normal_sensors:\n",
    "        if (android_ios_flag):\n",
    "            if (sensor == \"activity_ios\"): continue\n",
    "        else:\n",
    "            if (sensor == \"activity_android\"): continue\n",
    "        giant_table_sensor_pid_epoch = deepcopy(sensors_tables[sensor][\"epochs\"][epochs[0]])\n",
    "        for epoch in epochs[1:]:\n",
    "            giant_table_sensor_pid_epoch = giant_table_sensor_pid_epoch.merge(sensors_tables[sensor][\"epochs\"][epoch],\n",
    "                                                                             on = [\"date\", \"PID\"], how = \"outer\")\n",
    "        # reorder the table\n",
    "        cols_reorder = []\n",
    "        for col in sensors_tables[sensor][\"feature_cols\"]:\n",
    "            for epoch in epochs:\n",
    "                cols_reorder.append(col + \"_\" + epoch)\n",
    "        cols_reorder = [\"PID\", \"date\"] + cols_reorder \n",
    "        assert len(cols_reorder) == len(giant_table_sensor_pid_epoch.columns)\n",
    "        giant_table_sensor_pid_epoch = giant_table_sensor_pid_epoch[cols_reorder]\n",
    "        \n",
    "        # add sensor prefix\n",
    "        sensor_name = sensor\n",
    "        if (\"activity\" in sensor_name):\n",
    "            sensor_name = \"activity\"\n",
    "        giant_table_sensor_pid_epoch.columns = [sensor_name + \"_\" + x if x not in [\"PID\",\"date\"] else x for x in giant_table_sensor_pid_epoch.columns]\n",
    "            \n",
    "        if (giant_table_sensor_pid.shape[0] == 0):\n",
    "            giant_table_sensor_pid = deepcopy(giant_table_sensor_pid_epoch)\n",
    "        else:\n",
    "            giant_table_sensor_pid = giant_table_sensor_pid.merge(giant_table_sensor_pid_epoch, \n",
    "                                                                  on = [\"date\", \"PID\"], how = \"outer\")\n",
    "\n",
    "#     giant_table_sensor_pid = giant_table_sensor_pid.merge(df_sleep_merge, on = [\"PID\", \"date\"], how = \"outer\")\n",
    "    print(giant_table_sensor_pid.shape)\n",
    "    giant_table_sensor_pids.append(deepcopy(giant_table_sensor_pid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_sensor = pd.concat(giant_table_sensor_pids)\n",
    "# giant_table_sensor.set_index([\"PID\",\"date\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_columns = giant_table_sensor_pids[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_sensor = giant_table_sensor[original_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_sensor[\"date\"] = pd.to_datetime(giant_table_sensor[\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_sensor.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_rate = giant_table_sensor.isna().sum(axis = 0) / giant_table_sensor.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_sensor = giant_table_sensor.drop(empty_rate[empty_rate == 1].index,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "giant_table_sensor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the table for sleep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_sleep = pd.read_csv(path_to_sleep_merged_file)\n",
    "giant_table_sleep[\"PID\"] = giant_table_sleep[\"PID\"].apply(lambda x : \"pid{0:0>3}\".format(str(x)))\n",
    "giant_table_sleep[\"date\"] = pd.to_datetime(giant_table_sleep[\"date\"])\n",
    "# giant_table_sleep.set_index([\"PID\",\"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the table for EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_EMA = pd.read_csv(path_to_ema_merged_file,\n",
    "                             dtype = {\"discriminated\":str})\n",
    "giant_table_EMA[\"PID\"] = giant_table_EMA[\"PID\"].apply(lambda x : \"pid{0:0>3}\".format(str(x)))\n",
    "giant_table_EMA[\"date\"] = pd.to_datetime(giant_table_EMA[\"date\"])\n",
    "# giant_table_EMA.set_index([\"PID\",\"date\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the table for Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_baseline = pd.read_csv(path_to_baseline_merged_file)\n",
    "giant_table_baseline.rename(columns = {giant_table_baseline.columns[0]: \"PID\"},inplace = True)\n",
    "giant_table_baseline[\"PID\"] = giant_table_baseline[\"PID\"].apply(lambda x : \"pid{0:0>3}\".format(x))\n",
    "giant_table_baseline_pre = giant_table_baseline[giant_table_baseline[\"survey_type\"] == \"baseline2\"]\n",
    "giant_table_baseline_pre.set_index(\"PID\", inplace = True)\n",
    "giant_table_baseline_post = giant_table_baseline[giant_table_baseline[\"survey_type\"] == \"post\"]\n",
    "giant_table_baseline_post.set_index(\"PID\", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales_interested = [\n",
    "    \"BDI_II\",\n",
    "    \"CES_D\",\n",
    "    \"PSS\",\n",
    "    \"CHIPS\",\n",
    "    \"UCLA_Loneliness\",\n",
    "    \"ISEL\",\n",
    "    \"BRS\",\n",
    "    \"K2way_SSS\",\n",
    "    \"MLE\",\n",
    "    \"Sports\",\n",
    "    \"SF_12\",\n",
    "    \"MAAS\",\n",
    "    \"GMM\",\n",
    "    \"RSQ\",\n",
    "    \"STAI\",\n",
    "    \"ERQ\",\n",
    "    \"BFI_Extraversion\",\n",
    "    \"BFI_Agreeableness\",\n",
    "    \"BFI_Conscientiousness\",\n",
    "    \"BFI_Neuroticism\",\n",
    "    \"BFI_Openness\",\n",
    "    \"MSLQ\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_baseline_pre_selected = giant_table_baseline_pre[scales_interested]\n",
    "giant_table_baseline_pre_selected.columns = [x+\"_PRE\" for x in giant_table_baseline_pre_selected.columns]\n",
    "giant_table_baseline_post_selected = giant_table_baseline_post[scales_interested]\n",
    "giant_table_baseline_post_selected.columns = [x+\"_POST\" for x in giant_table_baseline_post_selected.columns]\n",
    "giant_table_baseline_pre_post_selected = giant_table_baseline_pre_selected.merge(\n",
    "                                            giant_table_baseline_post_selected,\n",
    "                                            how = \"outer\",\n",
    "                                            left_index = True,\n",
    "                                            right_index = True)\n",
    "giant_table_baseline_pre_post_selected.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge all tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuild the date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge with largest, then remove the date\n",
    "start_date = pd.to_datetime(\"2018-01-01\")\n",
    "end_date = pd.to_datetime(\"2018-06-30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = pd.date_range(start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebuild_table_with_all_dates(df):\n",
    "    giant_table_index_date = df.set_index(\"date\")\n",
    "    giant_table_grp_tmp = giant_table_index_date.groupby(\"PID\")\n",
    "    expanded_tablelist = []\n",
    "    pid_count = 0\n",
    "    for pid, giant_table_pid in giant_table_grp_tmp:\n",
    "        giant_table_index = pd.DataFrame(index = date_range)\n",
    "        giant_table_index = giant_table_index.merge(giant_table_pid, how = \"outer\",\n",
    "                                                    left_index=True, right_index = True)\n",
    "        giant_table_index[\"PID\"] = pid\n",
    "        expanded_tablelist.append(deepcopy(giant_table_index))\n",
    "        pid_count += 1\n",
    "    giant_table_rebuild = pd.concat(expanded_tablelist)\n",
    "    giant_table_rebuild.reset_index(inplace = True)\n",
    "    giant_table_rebuild.rename({\"index\":\"date\"}, axis = 1, inplace = True)\n",
    "    return giant_table_rebuild"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_sensor_rebuild = rebuild_table_with_all_dates(giant_table_sensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_sleep = rebuild_table_with_all_dates(giant_table_sleep)\n",
    "giant_table_EMA = rebuild_table_with_all_dates(giant_table_EMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge table by date and pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_sleep_EMA = giant_table_sleep.merge(giant_table_EMA,\n",
    "                                                how = \"outer\",\n",
    "                                                on = [\"PID\",\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_sleep_EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_sensor_sleep_EMA = giant_table_sensor_rebuild.merge(giant_table_sleep_EMA,\n",
    "                                                how = \"left\",\n",
    "                                                on = [\"PID\",\"date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_sensor_sleep_EMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# giant_table_sleep_EMA_baseline = giant_table_sleep_EMA.merge(giant_table_baseline_pre_post_selected,\n",
    "#                                                              how = \"outer\",\n",
    "#                                                              on = [\"PID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_sensor_sleep_EMA_baseline = giant_table_sensor_sleep_EMA.merge(giant_table_baseline_pre_post_selected,\n",
    "                                                             how = \"left\",\n",
    "                                                             on = [\"PID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the date\n",
    "giant_table_sensor_sleep_EMA_baseline = giant_table_sensor_sleep_EMA_baseline[\n",
    "#     (giant_table_sensor_sleep_EMA_baseline[\"date\"] >= pd.to_datetime(\"2018-1-21\")) & \n",
    "    (giant_table_sensor_sleep_EMA_baseline[\"date\"] <= pd.to_datetime(\"2018-6-15\"))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_sensor_sleep_EMA_baseline.to_csv(path_to_save_giant_table + \"\\giant_table_sensor_sleep_EMA_baseline.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "giant_table_sensor_sleep_EMA_baseline.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "543.2px",
    "left": "44px",
    "top": "93.4px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
